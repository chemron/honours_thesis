\documentclass[11pt,a4paper,onecolumn]{report}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{lmodern}
\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}
\usepackage{bm}
\usepackage[margin=2cm]{geometry}
\usepackage{array}
\usepackage{physics}
\usepackage{amssymb}
\usepackage{textcomp}
\usepackage[T1]{fontenc}
\usepackage{gensymb}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{enumerate}
\pagestyle{fancy}
\setlength{\headheight}{13.6pt}

\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows, calc}
\usepackage[nottoc, numbib]{tocbibind}
\tikzstyle{cool} = [rectangle, rounded corners, minimum width=3cm, minimum
height=1cm, text centered, draw=black, fill=gray!30, text width=3cm]
\tikzstyle{arrow} = [thick, ->, >=stealth] \tikzstyle{line} = [thick, -,
>=stealth]

\usepackage[detect-all]{siunitx}
\usepackage{dsfont}
\usepackage{breqn}
\usepackage{subfigure}
\usepackage{geometry}
\usepackage{listings}
\usepackage{caption}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{titlesec}
\usepackage[square,numbers,comma,sort&compress]{natbib}
\usepackage{upgreek}
\usepackage{aas_macros}
\usepackage{doi}
\usepackage{siunitx}
\usepackage{textgreek}


\geometry{a4paper, left=25mm, top=25mm,} % total={160mm,247mm} <- overspecification
\graphicspath{{figures/} }
\renewcommand{\listfigurename}{Figures}


\captionsetup{justification   = raggedright, singlelinecheck = false}

\hypersetup{colorlinks, citecolor=black, filecolor=black, linkcolor=black,
    urlcolor=black}

\renewcommand{\bibname}{References}

\bibpunct{(}{)}{;}{a}{}{,}

\hypersetup{colorlinks, citecolor=black, filecolor=black, linkcolor=black,
    urlcolor=black}


\newcommand*\chem[1]{\ensuremath{\mathrm{#1}}}

\newcommand{\threevdots}{%
  \vbox{\baselineskip1ex\lineskiplimit0pt%
  \hbox{.}\hbox{.}\hbox{.}}}



% diagnose: Label(s) may have changed. Rerun to get cross-references right.
% \def\@testdef #1#2#3{% \def\reserved@a{#3}\expandafter \ifx \csname
% #1@#2\endcsname \reserved@a  \else \typeout{^^Jlabel #2 changed:^^J%
% \meaning\reserved@a^^J% \expandafter\meaning\csname #1@#2\endcsname^^J}%
% \@tempswatrue \fi}


%opening
\title{Thesis}
\author{Cameron Smith\\
Student ID: 28792912\\
Supervisors: Andrew Casey, Alina Donea}
\date{\today}



\begin{document}


\begin{titlepage}
  \begin{center}
    \vspace*{2cm}
    \Huge
    \textbf{Title of your Thesis}

    \vspace{2cm}
    \LARGE
    \textbf{Cameron Smith}

    \vspace{0.8cm}
    \Large \textit{Supervisors:}\\
    Andrew Casey\\
    Alina Donea

    \vfill
    \large
    An honours thesis presented for the degree of\\
    Bachelor of Science Advanced - Research (Honours)

    \vspace{0.3cm}
    \includegraphics[width=0.2\linewidth]{"Monash_Logo"}\\
    School of Physics and Astronomy\\
    Faculty of Science\\
    Monash University\\
    Australia

    \vspace{0.5cm}

    \today

  \end{center}
\end{titlepage}

\chapter*{Abstract}



\chapter*{Acknowledgements}

\tableofcontents


\listoffigures







%
%
%
%
\chapter{Introduction}
%
%
%
%



%TODO: Introduction (maybe borrow slightly from lit review)


%
% Project outline from lit review
%

To train a cGAN to generate magnetograms from seismic maps, we require a
training set consisting of seismic maps and the corresponding magnetograms.
While the farside seismic maps are readily available\footnote{See
  \url{http://jsoc.stanford.edu/data/farside/}.}, corresponding magnetograms are
not. However, not all hope is lost. The STEREO-A spacecraft is in a heliocentric
orbit that traverses the Sun relative to the Earth, allowing it to observe the
farside during some points of the orbit. While STEREO-A does not capture
magnetograms of the Sun, it does take EUV images which can be used to create
magnetograms by using a cGAN \citep{Kim2019}.\\

A small complication is that no data is available from when STEREO-A was
directly opposite the Earth (between March and July 2015), due to the
interference from the Sun. This limits the ability to get magnetograms that
exactly coincide with the farside seismic maps. To compensate for this, we can
match farside seismic maps with images taken by STEREO-A at an earlier (later)
time when it is behind (ahead of) the farside, such that the same `face' of the
Sun is imaged due to it's rotation. After generating the magnetograms from the
STEREO-A EUV images, we can create a dataset of seismic maps with the
corresponding magnetogram (albeit with some time difference). This process is
summarised in Figure \ref{fig:Project_summary}.\\



\begin{figure}
  \centering
  \begin{tikzpicture}[node distance=5.5cm]
    % \draw[help lines] (0,-5) grid (10,10);
    \node (D) [cool, above=1.5cm] {SDO Dopplergram}; \node (P) [cool, right
      of=D] {Farside \quad \quad \quad \qquad  seismic map}; \node (E) [cool]
    {STEREO EUV image}; \node (M) [cool, right of=E, below=0.5cm] {STEREO
      Magnetogram}; \node (F) [cool, right of=M, above=1cm] {Farside\\
      Magnetogram}; \node (S) [cool, below=1.5cm] {SDO Magnetogram};

    \coordinate (FF) at ([xshift=-1.5cm]F.west); % we collect the edges in
    front of Q
    \coordinate (MM) at ([xshift=-1.5cm]M.west); % we collect the edges in
    front of Q

    \draw [arrow] (D) -- node[anchor=south, text width=2cm] {Helioseismic
      Holography} (P); \draw [arrow] (MM) -- node[anchor=south] {cGAN} (M);
    \draw [line] (P) -|  (FF); \draw [line] (M) -|  (FF); \draw [line] (S) -|
    (MM); \draw [line] (E) -|  (MM); \draw [arrow] (FF) -- node[anchor=south]
    {cGAN} (F);

  \end{tikzpicture}
  \caption[Project Pipeline]{Summary of the project. A cGAN is trained on SDO
    data to be able to generate EUV images. This is applied to STEREO EUV images
    to generate STEREO magnetograms. These are used in conjunction with farside
    seismic maps to train a new cGAN to generate magnetograms from seismic maps,
    allowing constant surveillance of the farside magnetic field.}
  \label{fig:Project_summary}
\end{figure}


% get some




%
%
%
%
%
%
\chapter{Background}
%
%
%
%
%
%


%
%
%
% Section: The Sun
%
%
%

\section{The Sun}
\label{sec:Sun}
% Formation of the Sun

The formation of the Sun began around 4.6 billion years ago, with a giant
molecular gas cloud approximately 65 light-years wide
\citep{montmerle_solar_2006}, which consisted of predominantly hydrogen, as well
as helium and trace amounts of lithium. \\

If one such cloud reaches a critical mass, the internal gas pressure will be
unable to continue supporting it, causing the cloud to undergo gravitational
collapse \citep{jeans_stability_1902}. This collapse leads to the formation of
potentially thousands of stars. Under the right conditions, massive (\(\gtrsim
\SI{9}{\,M_\odot} \)), short-lived stars in this cluster may explode as
supernovae \citep{heger_how_2003}, sending a shock through the molecular cloud
at high speeds. This can trigger the creation of more stars, which may go on to
also produce supernovae, giving rise to self-propagating star formation
\citep{mueller_propagating_1976}. The Solar System itself was likely formed in
this process, as part of a since dispersed cluster with a mass of around
\(\SI{3000}{\,M_\odot} \)\citep{williams_astrophysical_2010,zwart_lost_2009}. \\

As the Sun-forming fragment of molecular cloud collapses, it spins faster due to
the conservation of angular momentum. The molecules within begin colliding at an
increasing frequency, converting some of their kinetic energy to heat. The
centre of this collapsing nebula collects the majority of the mass to become an
increasingly hot and dense protostar, while the surrounding nebula flattens into
a protoplanetary disc. This mass becomes the building material for the solar
system, with the planets forming from the protoplanetary disk
\citep{greaves_disks_2005}. \\

As the Sun continues to contract, the temperature and pressure in the core
increases, eventually leading to fusion, at which point the Sun reaches it's
current stage of life as a main-sequence star \citep{woolfson_origin_2000}.
Proton-proton chain reaction (\textit{pp} chain) dominates this fusion process,
accounting for approximately $99\%$ of the Sun's energy, while the CNO cycle
generates the remaining \(\sim 1\%\) of the energy \citep{adelberger_solar_2011}.
The \textit{pp} chain process can be summarised as
\begin{align}
  \chem{p} + \chem{p} &\rightarrow \chem{\prescript{2}{}H} + \chem{e^+} +
  \nu_e \label{eqn:pp1}\\
  \chem{\prescript{2}{}H} + \chem{p} &\rightarrow \chem{\prescript{3}{}He}
  + \gamma \label{eqn:pp2}\\
  \chem{\prescript{3}{}He} + \chem{\prescript{3}{}He} & \rightarrow
  \chem{\prescript{4}{}He} + \chem{p} + \chem{p}\,, \label{eqn:pp3}
\end{align}
where Equations \ref{eqn:pp1} and \ref{eqn:pp2} must each occur twice to create
enough $\chem{\prescript{3}{}He}$ for Equation \ref{eqn:pp3} to occur. The
energy released by the fusion process comes in the form of gamma-ray photons,
heating the Sun from the inside, giving rise to the luminous hot ball of plasma
that we observe today. \\


Observation of the Sun is typically done through the use of either ground or
space-based telescopes. The Sun's atmosphere can be imaged at a range of depths
by viewing the Sun at different wavelengths, due to the variation in the Sun's
temperature and composition. Of particular note in this thesis is light with a
wavelength of \(\SI{304}{\angstrom}\), which is emitted in the chromosphere (the
layer of atmosphere between the photosphere and corona) by \(\chem{He \, II}\)
at a temperature of around \(\SI{50000}{\kelvin}\)
\citep{herbert_friedman_solar_1962}. \\

While electromagnetic radiation is effective for imaging the solar atmosphere,
past the photosphere (the Sun's visual surface, and henceforth referred to as
the surface) the Sun is no longer transparent to light, and so information about
the nature of the Sun below this surface must be inferred indirectly. \\


%
\subsection{Helioseismology}
%
\label{sec:HSM}

In \citeyear{leighton_velocity_1962}, \citeauthor{leighton_velocity_1962}
noticed oscillations of the Sun's surface varied with a period of \(\sim
5\) minutes. While initially assumed to be surface flows from solar granules,
further work found that the observed motion was due to the superposition of
resonant modes of oscillation in the Sun \citep{ulrich_five-minute_1970}. These
oscillations were later found to be a surface signature of pressure-modes
(p-modes) \citep{deubner_observations_1975}; standing waves generated by the
turbulent convective motion a few hundred kilometres below the surface. Pressure
is the dominant restoring force of p-modes (hence the name), effectively making
them sound waves (albeit at a far lower frequency than what is audible), with
frequencies ranging between 1 and 5 mHz. Unless propagating exactly radially,
these acoustic waves are continuously refracted as they travel deeper into the
Sun due to the changing speed of sound, eventually making their way back to the
surface. When they reach the surface, they are reflected back towards the
centre, effectively trapping them in a resonating cavity. \\

In addition to p-modes, two other types of modes exist in the Sun: gravity-modes
(g-modes) and surface gravity modes (f-modes). G-modes are confined to the
convectively stable radiative zone (from the core to a radius of $\SI{0.7}
{R_\odot}$), with buoyancy as the restoring force. F-modes also have buoyancy as
their restoring force, but instead travel along the surface of the Sun. \\

Each mode can be characterised by three quantum numbers: the radial order,
\(n\), the angular degree \(l\) (\(l \geq 0\)), and the azimuthal order m (\(-l
\leq m \leq l\)). Each mode has a resonant frequency \(\omega_{nlm}\) which
increases monotonically with \(n\), and can be measured by taking a Fourier
transform of the observed oscillations. In spherically symmetric conditions, the
frequencies of these modes would be independent of \(m\), however, this is not
observed, with the internal rotation of the Sun breaking this symmetry. P-modes
make up the high-frequency modes (with \(n>0\)), while g-modes make up the
low-frequency modes (with \(n<0\)). F-modes are then the intermediate mode, with
\(n=0\). Figure \ref{fig:hsm_power} shows a power spectrum of the p-mode
oscillations, as a function of frequency and angular degree. \\

\begin{figure}[t]
  \centering
  \subfigure[]{
    \includegraphics[height = 2in]{hsm_power_spectrum.png}
    \label{fig:hsm_power}
  }
  \subfigure[]{
    \includegraphics[height = 2in]{sound_speed.jpg}
    \label{fig:sound_speed}
  } \caption{\subref{fig:hsm_power} Power spectrum of the Sun's p-mode
  oscillations. Each ridge corresponds to a different value of \(n\).
  \textit{Image by Warrick Ball, using data from the Michelson Doppler Imager
  (MDI) aboard the Solar and Heliospheric Observatory (SOHO). Distributed under
  a CC BY-SA 4.0 license}. \subref{fig:sound_speed} The speed of sound
  (\(\si{km\per s}\)) inside the Sun as a function of the fractional radius
  (\(\si{r \per R_\odot}\)) \citep{bahcall_solar_2000}.}

\end{figure}

These modes are influenced by the structure and gravity inside the Sun, as well
as the large scale flows and magnetic fields. When the perturbations from these
resonating waves reach the surface of the Sun, the motion creates surface
oscillations, while the local change in pressure causes a fluctuation in the
temperature. Detecting the modes can therefore be achieved by observing either the
luminosity or the Doppler shift.\\

The goal of helioseismology is to observe these modes and deduce the causal
factors that influence them, thereby obtaining information about the solar
interior. While g-modes offer the potential to probe the inner core of the Sun,
the amplitude of the resulting perturbations will be very low by the time they
reach the surface. Consequently, the detection of g-modes has so far proved
elusive \citep{appourchaux_quest_2010}, with only a few possible exceptions (for
example, \citealp{fossat_asymptotic_2017}). P-modes on the other hand, while
unable to probe as deep into the Sun, have proven much easier to observe and
examine \citep{deubner_observations_1975}. \\

By measuring the frequency of p-modes in the Sun, helioseismology can be used to determine
the speed of sound as a function of the radius, \(c\left(r\right)\)
\citep{christensen-dalsgaard_speed_1985}, which can in itself be used to
determine the temperature as a function of the radius, \(T\left(r\right)\), due
to the relationship
\begin{align}
  c^2 = \frac{\bar{R}\Gamma_1 T}{\mu} \,,
\end{align}
where \(\bar{R}\) is the gas constant, \(\Gamma_1\) is the adiabatic exponent,
and \(\mu\) is the mean molecular weight. The `bump' seen in Figure
\ref{fig:sound_speed} around \(\SI{0.7}{r \per R_\odot}\) indicates the point where the
Sun becomes convectively unstable, and the dominant form of energy transport
transitions from radiation to convection, allowing helioseismology to determine
the precise depth of the convective zone
\citep{christensen-dalsgaard_speed_1985}. Similarly, the dip in the sound speed
at the centre of the Sun is a signature of the fusion in the core, which gives
insight into both the current fusion process and the history of nuclear
reactions. \\

% In the convective zone, the gradient of the temperature (and therefore speed of
% sound) is influenced by the opacity of the plasma to radiation, 


% rotation of the Sun

From the frequency splittings of p-modes, it is possible to determine the
angular velocity of the Sun as a function of radius and latitude
\citep{schou_helioseismic_1998}. Figure \ref{fig:internal_rotation} shows the
result of such a process, based on Doppler data from the Michelson Doppler
Imager (MDI) aboard the Solar and Heliospheric Observatory (SOHO). From this
process, it is now known that the convective zone is differentially rotating
with rotation rates that vary with latitude \citep{eff2012dynamics}. Within the
convective zone, the period of the rotation is approximately 25 days at the
equator and approximately 35 days near the poles \citep{hughes2007solar}. This
is in agreement with surface measurements of the rotation based on the motion of
sunspots across the Sun \citep{schou_helioseismic_1998}. \\


% tachocline
Beneath the convection zone in the radiative zone and core, the Sun appears to
exhibit almost solid-body rotation. However, the uncertainties on these
measurements become much greater towards the core. There is a thin layer
(\(\sim \SI{28000}{km}\) thick) separating the convective and radiative zone which
experiences a large shear due to the rapid change of rotation
\citep{spiegel1992}. This transition region is called the tachocline and is
widely thought to be the location where the Sun's large scale magnetic fields are
generated by the solar dynamo.

\begin{figure}[t]%
  \centering
  \subfigure[]{%
    \label{fig:internal_rotation}%
    \includegraphics[height=2in]{internal_rotation.png}% 
  }%
  \qquad
  \subfigure[]{%
    \includegraphics[height=2in]{tacholine_rotation.png}%
    \label{fig:tacholine_rotation}%
  }%
  \caption[]{\subref{fig:internal_rotation} The rotation of the convective zone
    in the Sun, as inferred by global helioseismology
    \citep{thompson_helioseismology_2004}. \subref{fig:tacholine_rotation} The
    rotation rate as a function of latitude and depth, showing differential
    rotation in the convective zone and nearly uniform rotation in the radiative
    zone. \textit{Image Courtesy of Global Oscillation Network Group
    (GONG)\footnotemark }.}
\end{figure}



%
% TODO: is this still a relevant title?
\subsection{The Solar Magnetic field}
%
\label{sec:dynamo}
%TODO: make sure this lines up
\footnotetext{\url{https://gong.nso.edu/}}

By using the Zeeman effect---the splittings of the spectral lines in the presence of
a strong magnetic field---we can observe magnetic fields on the surface of
the Sun \citep{zeeman_over_1896}. This was first done by \citet{hale_probable_1908}, who noticed the
intense magnetic fields of sunspots, and presently can be used to make full-disk
solar magnetograms, such as the one shown in Figure \ref{fig:hmi}.
\\
\begin{figure}[t]
  \centering
  \includegraphics[width=0.4\linewidth]{hmi.jpg}
  \caption{Magnetogram taken by the Solar Dynamics Observatory's Helioseismic
  Magnetic Imager on 17 November, 2014. \textit{Image courtesy of NASA}.}
  \label{fig:hmi}
\end{figure}


These sunspots are now known to be surface manifestations of a large scale solar
magnetic field consisting of a poloidal (north-south) and toroidal (east-west)
component originating inside the Sun. \citet{JosephLarmor1919} suggested that
these large scale magnetic fields are generated by the inductive motion of the highly
conductive plasma, as part of a solar `dynamo'. For such a dynamo to exist, it
must convert the kinetic energy of the differentially rotating plasma into a
self-regenerating magnetic field, with the poloidal component somehow creating
and strengthening the toroidal component and vice versa. \\



While there are currently many dynamo theories (see
\citealt{charbonneau_dynamo_2020} for example), there is currently no consensus as
to the exact mechanism of the dynamo. Perhaps the biggest clue for finding a
dynamo model comes from sunspot observations. A successful dynamo model must be
able to replicate the almost 400 years of scientific observations from
\citet{galilei_sunspots_2010} to the present day. Importantly, such a model
must account for the following phenomena:

\begin{enumerate}
  \item Sunspot activity takes place over 11 year `solar cycles', where the size
  and number of sunspots on rises to a `solar maximum', then falls to a `solar
  minimum' \citep{schwabe_astronomische_1844}. Figure \ref{fig:sunspot_area}
  shows this solar cycle over the last 400 years, including the `Maunder
  Minimum', a period of around 70 years which saw very few sunspots.

  \item As can be seen in Figure \ref{fig:butterfly diagram}, the location of sunspot
  formation is restricted to two latitudinal bands approximately \(30\degree\)
  wide, mirrored each side of the equator. These bands converge toward the equator
  over the course of the solar cycle, ultimately covering around \(\pm 15\degree\)
  in latitude before starting over again in the next cycle
  \citep{carrington_observations_1863}. This is known as Sp\"orer's law.

  \item Sunspots tend to form in pairs of opposite polarity. Over the course of the
  solar cycle, the polarity of the leading sunspots of each pair (with respect
  to the rotation of the Sun) is typically the same across the hemisphere, and
  opposite to the leading sunspots in the opposite hemisphere
  \citep{hale_law_1925}. For example, in solar cycle 24 (2008 to 2019) leading
  sunspots typically had a negative polarity in the northern hemisphere and a
  positive polarity in the southern hemisphere, while in solar cycle 25, this is
  reversed. This is known as Hale's law and is shown in Figure
  \ref{fig:mag_butterfly}, over the duration of four solar cycles.

  \item Large sunspot pairs often emerge with a systematic tilt, with the
  leading sunspot closer to the equator than the trailing sunspot
  \citep{hale_magnetic_1919}. This is known as Joy's law.
\end{enumerate}


\begin{figure}[t]%
  \centering
  \subfigure[]{%
    \includegraphics[width=0.6 \linewidth]{sunspot_area.png}%
    \label{fig:sunspot_area}%
  }\\%
  \subfigure[]{%
    \label{fig:butterfly diagram}%
    \includegraphics[width= 0.8\linewidth]{ButterflyDiagram.png}%
  }\\%
  \subfigure[]{%
  \includegraphics[width=0.8\linewidth]{magbfly.png}%
  \label{fig:mag_butterfly}%
  }%
  \caption[]{\subref{fig:sunspot_area} The number of sunspots observed on the
  solar surface as a function of time, over the course of the past 400 years.
  \textit{Image by Robert A. Rohde, as part of the Global Warming Art project.
  distributed under a CC BY-SA 3.0 license}. \subref{fig:butterfly diagram} A
  `Butterfly diagram' of the Sun, showing the evolution of sunspots over the
  course of many solar cycles. \textit{Image courtesy of NASA}.
  \subref{fig:mag_butterfly} A Butterfly diagram of the Sun, this time showing
  the magnetic field of the sunspots. \textit{Image courtesy of NASA}. }
\end{figure}

Furthermore, as can be seen in Figure \ref{fig:mag_butterfly} near the poles,
the sign of the poloidal magnetic field flips in the middle of each solar cycle,
near the point of maximum solar activity, while the sign of the toroidal field
flips between each cycle, as indicated by Hales law. As such, the solar dynamo
must complete a full cycle over the course of 22 years (two solar cycles), with the
poloidal (\(P\)) and toroidal (\(T\)) fields been generated as follows:
\begin{align}
  P^+ \rightarrow T^- \rightarrow P^- \rightarrow T^+ \rightarrow P^+ \rightarrow \dotsc\,,
  \label{eqn:dynamo process}
\end{align}
where (\(^+\)) and (\( ^-\)) are the signs of the magnetic fields. \\

Putting even more constraints on a dynamo model, \citet{cowling1933} showed that
`An axis-symmetric magnetic field cannot be maintained by dynamo action'.
Subsequent `antidynamo' theorems by \citet{backus1956} and others have
concluded that a dynamo powering the Sun's magnetic field must not possess a
high degree of symmetry and so necessarily must be the result of a more complex
mechanism.\\


To find such a mechanism, we require an understanding of the interplay between the
motion of the highly conductive plasma and the changing magnetic field.
Magnetohydrodynamics gives us this necessary insight by combining the
equations of fluid dynamics with that of electromagnetism. Perhaps the principle
equation of magnetohydrodynamics is the ideal induction equation, which can be expressed as
\begin{align}
  \partialderivative{\bm{B}}{t} &=
  \nabla \crossproduct \left(\bm{v}\crossproduct \bm{B}\right)\,.
  \label{eqn:ideal_induction}
\end{align}
A full derivation of the induction equation is shown in Appendix
\ref{sec:induction_eqn}. Any successful dynamo theory must therefore provide a
velocity field, \(\bm{v}\), and a magnetic field, \(\bm{B}\), that satisfies
this equation. \\

Using the induction equation it can be shown that in the limit of infinite
electrical conductivity, magnetic field lines are `frozen' into the Sun's plasma
and must move along with it \citep{Alfven1943}. The consequence of this is a
continuous struggle between the magnetic field and flow of the plasma, where
strong magnetic fields will pull on the plasma, while strong currents will pull
on the magnetic field. These magnetic field lines may therefore organise into
`flux tubes': cylindrical boundaries along magnetic field lines that move with
the plasma. \\

As depicted in Figure \ref{fig:dynamo}(b), because of this effect, as well as
the differential rotation of the Sun, the plasma pulls on initially poloidal
field lines more strongly the closer they are to the equator. After many
rotations, this results in the twisting of the poloidal field lines into
toroidal ones (Figure \ref{fig:dynamo}c). This process is called the
\textomega-effect. The depth where this mechanism occurs is subject to some
debate, with dynamo theories placing it in either the tachocline (for example
\citealt{deluca_dynamo_1988}) or the convective zone (for example
\citealp{chen_emergence_2017}). The \textomega-effect accounts for the first
half of the dynamo mechanism (\(P \rightarrow T\)) and is relatively well
understood.\\

%
While the mechanism for generating a poloidal field from a toroidal field (\(T
\rightarrow P\)) is much more contentious, it is very likely tied to the
formation and evolution of sunspots. The current leading model of sunspot
formation was first introduced by \citet{parker_formation_1955}. In this model,
a toroidal flux `rope' consisting of many individual flux tubes becomes buoyant
and rises to the surface of the Sun. The balance of pressures inside and outside
this flux rope is given by,
\begin{align}
  P_{B,i} + P_{G,i} &= P_{G,e}\,,
\end{align}
where \(P_{B,i}\) is the internal magnetic pressure, \(P_{G,i}\) is the internal
gas pressure and \(P_{G,e}\) is the external gas pressure. By definition of the
respective pressures, this can be formulated in terms of the densities as
follows:
\begin{align}
  \label{eqn:density balance}
  \frac{\bm{B}^2}{2\mu_0} + \rho_i \frac{k_B T_i}{\mu} &= \rho_e \frac{k_B T_e}{\mu}\,,
\end{align}
where \(\mu_0 \) is the magnetic permeability, \(k_B\) is Boltzmann's constant,
\(\mu\) is the mean molecular weight, \(\rho_i\) and \(\rho_e\) are the internal
and external density, and \(T_i\) and \(T_e\) are the internal and external
temperatures.\\

\noindent As the first term on the right-hand side of Equation \ref{eqn:density balance}
is always positive, we have:
\begin{align}
  \label{eqn:density_temp}
  \rho_i T_i &< \rho_e T_e\,.
\end{align}
If the internal and external temperatures are equal, the internal density will
be less than the external density. Furthermore, if the flux rope is rising through
the Sun, it will typically have a higher temperature than its surroundings as
it comes from a hotter region of the Sun. Therefore, Equation
\ref{eqn:density_temp} reduces to:
\begin{align}
  \rho_i < \rho_e\,,
\end{align}
and so the flux rope will experience an upward buoyancy force. This
buoyancy force competes with a magnetic tension in the flux rope, causing it to
stretch as rises. \\

As such a flux rope begins to rise, it may begin to twist due to
cork-screw-shaped `cyclonic' vortices in the turbulent flow in the convective
region \citep{parker_formation_1955}. The Coriolis effect causes vortices in the
northern hemisphere to spin in the opposite direction to those in the southern
hemisphere due to the rotation of the Sun, analogous to how cyclones behave on
the Earth. These twisting flux ropes would break off from the toroidal field,
and form loops in the meridional plane as can be seen in Figure
\ref{fig:dynamo}(c). Importantly, this process would break the axis symmetry
prohibited by the aforementioned antidynamo theorems, and also explain the
equatorial tilt that constitutes Joy's law. The net effect of these loops around
the Sun would be to create a toroidal current according to Ampere's law, which
in turn would contribute to the large scale poloidal magnetic field. This
process was first introduced by \citet{parker_hydromagnetic_1955} and comprises
the \textalpha-effect. In principle, a combination of the \textalpha-effect and
the \textomega-effect can complete the dynamo process shown in Equation
\ref{eqn:dynamo process}. As the flux rope breaks the surface, it forms an
`\(\Omega\)-loop' and creates an active region with sunspots of opposite
polarity at each entry point. \\

While the stability and rise of these flux ropes is now reasonably well
understood, the process in which the large scale magnetic field produces the
necessarily concentrated toroidal flux ropes remains unknown. However at the
very least, if we assume that sunspots rise approximately radially and that
a stronger toroidal field generates stronger and more frequent sunspots, the
location and strength of sunspots can provide a map of the toroidal magnetic
field. Under this assumption, `Butterfly' diagrams, such as the ones shown in
Figures \ref{fig:butterfly diagram} and \ref{fig:mag_butterfly}, provide a
useful tool for mapping the long term trends and of the toroidal magnetic field
throughout each solar cycle, aiding numerical simulations. \\

\begin{figure}[t]
  \centering
  \includegraphics[width=0.6\linewidth]{dynamo.png}
  \caption{(a) An initial poloidal magnetic field. Due to the
  \textomega-effect, this field is pulled in the toroidal direction (b),
  eventually creating a toroidal field (c). This toroidal field results in the
  formation of sunspots (c), which in turn generate the large scale poloidal field
  (d) \citep{carroll2006}.}
  \label{fig:dynamo}
\end{figure}


Another process that contributes toward the poloidal magnetic field is the
Babcock-Leighton mechanism. Due to the tilt observed in Joy's-law, some
component of the magnetic dipole in a bipolar-sunspot-pair is in the north-south
direction. As the sunspot pair disperses over time, the surface flows release
some amount of this dipole moment, contributing to the overall poloidal field
\citep{babcock_topology_1961,leighton_transport_1964}. This can be seen in
Figure \ref{fig:mag_butterfly}, near the top of each hemisphere. In principle,
this can in itself lead to a working dynamo, by generating the poloidal field
from the toroidally generated sunspots. \\


Despite many years of research into the solar dynamo, there is much that still
remains unclear, with many questions remaining. In particular, this includes:
\begin{enumerate}
  \item What mechanism is predominantly responsible for converting a toroidal
  field to a poloidal one?

  \item Is the Babcock-Leighton mechanism a crucial part of the dynamo
  mechanism, or just a side-effect of decaying Sunspots?

  \item How constraining is the butterfly diagram? I.e can the structure of the toroidal field be
  directly inferred from the distribution of the Sunspots?

  \item Is the tachocline a crucial part of the dynamo mechanism?

  \item What is the cause of periods such as the Maunder Minimum?
\end{enumerate}
A better understanding of the dynamo will lead to a better understanding of the Sun
and all stars in general. Furthermore, a stronger grasp of the working of the
solar magnetic field, and therefore of sunspots, will be critical in our ability
to predict and prepare for extreme space weather events.








\section{Space weather}
%  Solar flares
%   coronal mass ejection's
%  STEREO spacecraft (3d model of coronal mass ejections)
%     Effects on earth
%  How it is modelled
%  Magnetograms
% Currently they use the flux transport model (ADAPT)
%   full sun magnetograms (currently created by assuming magnetic field doesn't
%   change in the farside,
%i.e. farside is just nearside from half a rotation earlier)
%  how farside magnetograms could help with this



Magnetic activity on the surface of the Sun can at times cause large eruptions
on the solar surface, potentially emitting high-intensity x-rays or ejecting
plasma out into the heliosphere and beyond. While ordinarily harmless, extreme
space weather events can have major consequences, for instance hazardous radiation exposure
to astronauts or significant damage to terrestrial electricity grids. The most extreme
of these space weather events are solar flares and coronal mass ejections. \\


These eruptive events occur in active regions, which as the name
suggests, are magnetically active regions of the Sun that typically consist of
one or more sunspots. Like the bipolar sunspot pairs discussed in Section
\ref{sec:dynamo}, these active regions are generated by the toroidal magnetic
field and rise through the convective layer of the Sun as flux ropes. As these
flux ropes rise, they can twist and kink, often forming knots, leading to the
formation of the more complex active regions \citep{linton_helical_1996}. As they surface,
these newly formed active regions undergo horizontal expansion, known as `pancaking',
releasing some of the accumulated magnetic energy
\citep{toriumi_flare-productive_2019}.\\

Any current in an active region is unable to dissipate efficiently due to
the high conductivity of the plasma. This leads to the build-up in magnetic energy, as the
forces of magnetic pressure, magnetic tension, and gravity cause the flux ropes
in an active region to twist and shear. If the active region is unable to disperse this energy, this
ultimately results in a magnetic reconnection event, where twisted field lines
pointing in opposite directions converge and explosively realign causing a large
release of built-up magnetic energy. This eruption
pushes the flux rope into the higher atmosphere, carrying with it much of the
overhead coronal magnetic field. If the flux rope is ejected successfully, it
forms the magnetic structure of a coronal mass ejection, propelling particles and electromagnetic
radiation outwards into space. This process is known as the `CSHKP' model, named after
the leading researches behind it \citep{carmichael_process_1964,
sturrock_model_1966, hirayama_theoretical_1974, kopp_magnetic_1976}. A visual
depiction of the CSHKP model is shown in Figure \ref{fig:flare_model}. \\


The release of energy in these magnetic reconnection events creates a localised
flash of intense light in the corona, constituting a solar flare
\citep{priest_solar_1984}. X-rays from such a flare can heat the outer
atmosphere of the Earth and increase the drag on satellites at low orbits
\citep{Oliveira2019}, while energetic protons released by a solar flare can
pose a radiation hazard to potential astronauts \citep{Mewaldt2005,
lamarche1996}. This is of particular relevance now, with the recent announcement
of planned missions to land astronauts on the Moon again by 2024, and Mars in
the 2030s \citep{smith_artemis_2020}. \\


Coronal mass ejections pose an even greater hazard to human activity. When a
coronal mass ejection collides with the Earth's magnetic field, it creates a
geomagnetic storm. This deforms the magnetic field and can induce currents in
conductive materials on the Earth in an extreme event. While this has only a
small effect locally, over large scales (such as the long power lines connecting cities), the
cumulative effect can be potentially catastrophic. The Carrington Event in 1859
\citep{carrington_description_1859, hodgson_curious_1859} was the largest such
event ever recorded \citep{cliver_1859_2004}, causing disruptions to North
American and European telegraph systems, with some telegraph operators
experiencing electric shocks (National Research Council,
\citeyear{council_severe_2008}). A smaller geomagnetic storm was observed in
1989 and resulted in communication blackouts due to radio interference, loss of
control from multiple satellites, and mass power outages in Quebec
\citep{odenwald_day_2015}. Due to the large scale electrical grids currently in
place around the world, an event of similar magnitude to the Carrington Event
has the potential to overwhelm electrical grids on a much greater scale. The
National Research Council (\citeyear{council_severe_2008}) estimated that the
recovery of a severe geomagnetic storm would take between 4 and 10 years, and
cost between one and two trillion USD in the first year alone. \\


Prediction and early warning of potentially eruptive active regions is therefore
vital due to the potential hazards. To this end, it is helpful to classify the
different types of active regions. The commonly used Mount Wilson classification
is as follows \citep{martres_etude_1966}:
\begin{itemize}
  \item \(\alpha\): a unipolar sunspot group,
  \item \(\beta\): a bipolar sunspot group with a clear division between the polarities,
  \item \(\beta \gamma\): a complex active region where no single continuous
  line can separate the polarities, and
  \item \(\gamma\): a complex active region with no simple division between the polarities.
\end{itemize}
The qualifier \(\delta\) is used when at least two sunspots of
opposite polarity have umbrae (the centre of the sunspot) separated by less than
two degrees. \\

The probability of eruption increases with the complexity and size of the
active region in the order listed above \citep{giovanelli_relations_1939}. This
relationship is clearly seen in Figure \ref{fig:flare_occurance}. Modern
predictive methods typically use machine learning, based on a set of chosen
parameters, to determine the probability of an active region eruption, and therefore
identify potentially dangerous active regions. For example,
\citet{bobra_solar_2015} used a machine learning algorithm, called support
vector machines, to classify active regions as either flaring or non-flaring. This was
based on magnetograms taken by the Solar Dynamics Observatory's Helioseismic
magnetic imager, using 25 different features of the active region, such as the area and the
total unsigned magnetic flux. \\


However methods such as this have a severe limitation in that any active region
will only be visible for \(\sim 7\) days before directly facing the Earth due to
the rotation of the Sun. To give more advanced warning of potentially dangerous
active regions, a method of imaging the farside magnetic field is needed. \\

\begin{figure}[t]%
  \centering
  \subfigure[]{%
    \includegraphics[height=3in]{flare_occurance.jpg}
    \label{fig:flare_occurance}
  }%
  \qquad
  \subfigure[]{%
    \includegraphics[height=3in]{flare_model.jpg}
    \label{fig:flare_model}
  }%
  \caption{\subref{fig:flare_occurance} The peak flare intensity compared to
  size, for the different active region classes \citep{sammis_dependence_2000}.
  \subref{fig:flare_model} The CSHKP model for a solar flare with a coronal mass
  ejection. The black circles represent regions that can be directly probed with
  hard x-ray observations \citep{Christe2017}}.
\end{figure}







\section{Farside Helioseismic Holography}
\label{sec:FHSM}

% Halo thing (Alina)
% why we can't currently measure the farside or farside magnetic field continuously
%  farside helioseismic holography
% Use of gans to 
%  how this could be used in image-to-image translation to generate farside magnetograms


In Section \ref{sec:HSM} we discussed global helioseismology, the
study of the precise frequencies of the Sun's resonant modes. This can be used
to infer properties about the Sun, such as structure or rotation, as a function
of radial depth and latitude, but gives no details about how these aspects may
change with latitude. Local helioseismology on the other hand instead looks at
spatially compact anomalies in the observed p-modes, caused by some disturbance
\citep{braun_absorption_1988}. Where global helioseismology is analogous to
`hearing' the Sun, local helioseismology is analogous to `seeing' the Sun. Of
particular interest in this thesis is farside helioseismic holography, which
uses the interaction between p-modes and active regions to map the farside of
the Sun. \\

% so far we have used globa helioseismology
% rotation, structure etc

%local helioseismology

% The p-modes used in farside helioseismology propagate downwards from the outer
% convection one, retaining a strong coherence as they travel. If a p-mode
% intercepts an active regions on the Sun's surface, they carry a signature of
% this interaction as they continue to travel. When the encounter the Sun's
% surface, they leave detectable signals, before undergo specular reflection,
% reflecting back into the Sun. This continues for multiple `skips' before they
% either lose coherence or decay (see Figure \ref{fig:skips}).\\

A computational model of the Sun's surface and interior must first be constructed for
any helioseismic holography study. Any acoustic sources or waves in this model
are expressed in terms of an acoustic field, \(\psi\). Disturbances in \(\psi\)
propagate outwards with `bubble'-like wavefronts (see Figure
\ref{fig:egression}). The only part of this model that can be directly observed
is the disturbances that reach the surface, \(S_0\). A record of these surface
disturbances, \(\psi_0\), is then applied to the model. This model is then run
backwards in time, giving a time-reversed acoustic field, \(H_+(\bm{r}, t)\)
(also called the `coherent acoustic egression'), which gives a measure for the
disturbances on a `sampling surface' that travels backward in time with the
acoustic egression through the solar interior (see Figure \ref{fig:egression}).
The acoustic power on this surface is then given by \(\abs*{H_+(\bm{r},
t)}^2\).\\

\begin{figure}[t]%
  \centering
  \subfigure[]{%
    \label{fig:skips}%
    \includegraphics[height=2in]{skips.png}% 
  }%
  \qquad
  \subfigure[]{%
    \includegraphics[height=2in]{egression.jpg}%
    \label{fig:egression}%
  }%
  \caption[]{\subref{fig:skips} Depiction of p-modes propagating through the solar
    interior \citep{Lindsey2017}. \subref{fig:egression} Disturbances on the solar surface (dark blue) can be
    computationally propagated backward in time to a sampling surface. The
    acoustic power is then given by the squared magnitude of this coherent
    acoustic egression.\citep{Lindsey2011} }
\end{figure}


Farside helioseismic holography uses this same concept but also takes advantage of
the diffraction of the p-modes that occurs in the Sun. The diffraction of sound
waves when crossing between two different mediums is given by Snell's law,
\begin{align}
  c_0 \sin \theta = c \sin \theta_0 \,,
\end{align}
where \(c_0\) and \(\theta_0\) are the speed of sound and the angle from the normal
in the initial medium, while \(c\) and \(\theta\) are the speed of sound and
angle from the normal in the medium the wave travels to
respectively\footnote{The normal referenced is the normal to the surface
separating the two mediums,}. Rearranging this in terms of a constant \(K = \sin
\theta_0 / c_0 \), we get
\begin{align}
  \sin \theta = Kc \,.
\end{align}
Approximating the Sun as spherically symmetric, with a sound speed dependent
only on the radial distance from the centre, \(r\), Snell's law transforms to
\begin{align}
  r\sin \theta = Kc \,,
\end{align}
with the initial condition, \((\theta_0, c_0)\), and the new constant,
\begin{align}
  K = \frac{R_\odot \sin \theta_0}{c_0}\,.
\end{align}
The consequence of this is that p-modes travel in the curved paths shown in
Figure \ref{fig:skips}, `skipping' when they reach the surface due to the
specular reflection. Figure \ref{fig:pupil} illustrates how the acoustic waves
can travel to (green arrows) and from (yellow arrows) the `focus' on the
farside. \\

Active regions are strong absorbers of acoustic waves unless the waves approach
in a direction close to the normal of the surface \citep{Braun1989,
lindsey_seismic_2000, braun_surface-focused_2008}, as is the case of those with
skip distances like that of the ones shown in Figure \ref{fig:pupil}. However,
while they do not absorb these approximately normally incident waves, they do
impart a phase shift of a fraction of a radian upon them, which in turn, causes
the echo to reach the nearside a few seconds earlier than it otherwise would
have. This may be due to a physical depression observed in sunspots, called
the Wilson depression \citep{Lindsey_2010}.\\

To detect farside active regions, the p-modes travelling
from the nearside to the focus are compared to the echo that comes back to the
nearside. While the echo is modelled with coherent acoustic egression introduced
above (\(H_+(\bm{r}, t)\)), the waves travelling toward the farside are modelled with
`coherent acoustic ingression', \(H_-(\bm{r}, t)\), which is the time-forward
equivalent. By comparing these two for various pupils, a map of the phase-shifts
and therefore a map of potential farside active regions can be created.
Composite images of the farside seismic map and the corresponding nearside
magnetograms are shown in Figure \ref{fig:phase_map}.\\

\noindent The spatial resolution of this technique is limited by the Abbe
diffraction limit,
\begin{align}
  \Delta s &= 1.22\frac{\lambda_0}{2 \sin{\theta_0}}\,,
\end{align}
where \(\lambda_0\) is the wavelength of the p-mode and \(\theta_0\) is the
`opening angle' of the focus (see Figure 7a). For a double skip,
such as the one shown in Figure \ref{fig:skips}, we have an opening angle of
\(\theta_0 =2.9\degree\), which gives a spatial resolution of \(\Delta s =
10\degree\) of the Sun's surface. For a single skip, we have \(\theta_0
=0.33\degree\), giving the significantly worse spatial resolution of \(\Delta =
87\degree\). \\

\begin{figure}[t]%
  \centering
  \subfigure[]{%
    \label{fig:pupil}%
    \includegraphics[height=3in]{pupil.png}%
  }%
  \qquad
  \subfigure[]{%
    \includegraphics[height=3in]{phase_map.png}%
    \label{fig:phase_map}%
  }%
  \caption[]{
    \subref{fig:pupil} Diagram showing the paths taken by the wavefronts
    travelling to the focus (green) before echoing back from the focus (yellow)
    \citep{Lindsey2011}.\\
    \subref{fig:phase_map} Images showing both a farside seismic map created using
    farside helioseismic holography (yellow) and a nearside magnetogram (blue).
    As the Sun rotates, active regions can be seen moving from the farside to
    nearside. The seismic map is measured by the time perturbation, \(\tau\) caused by
    potential active regions \citep{Lindsey2017}.
    }
\end{figure}


In practice, farside helioseismic holography has been used to produce farside
seismic maps every 12 hours by Stanford's Joint Science Operations
Center\footnote{See \url{http://jsoc.stanford.edu/data/farside/}.}. Both \(H_+\)
and \(H_-\) are calculated over 24 hour (overlapping) periods, using
dopplergrams taken by the Solar Dynamics Observatory's Helioseismic
Magnetic Imager (SDO/HMI). This process takes \(31 \) hours, due to the \(7\) hour
travel time of the acoustic waves. \\


While there is a known correlation between the seismic signatures and the
magnetic flux of an active region \citep{Gonzalez_Hernandez_2007}, a direct relationship
between the phase shift and the magnetic field is unknown, preventing accurate
prediction of potentially dangerous active regions. However, due to the large amounts of data
available, recent machine learning techniques offer the potential of finding
such a relationship.



%
%
\section{Deep learning}
%
%

% Machine learning
% Supervised vs unsupervised
% regression
% structure
% Input
% Fully connected layer
% Convolutional layers
% Learning
% Gradient descent
% Backprop
% Gans
% cGans
% how they could be used to generate farside magnetograms
\label{sec: deep learning}
Machine learning is the process of a computer algorithm improving at some task
through `experience'. In supervised learning (as opposed to unsupervised
learning), this task is to learn some function based on training examples,
each consisting of an input, \(\bm{x'}\), and a corresponding desired output,
\(\bm{y'}\). After training, the resulting function would ideally be able to
take a new input, \(\bm{x}\), and return an appropriate output, \(\bm{y}\). \\

In supervised deep learning this function takes the form of an artificial neural
network, essentially a large composite function:
\begin{align}
  \bm{y} &= NN(\bm{x}, \bm{\theta})\\
  &= L^{[n_L]}(\bm{\theta}^{[n_L]}, L^{[n_L-1]}( \dotsm L^{[1]}(\bm{\theta}^{[1]}, \bm{x}) \dotsm ))\,, 
\end{align}
where each function \(L^{[i]}\) is a `layer' with parameters
\(\bm{\theta}^{[i]}\), and \(n_L\) is the total number of layers. The `deep' in deep
learning refers to the large number of layers between the input and output.
Training is therefore the process of tuning the parameters of the neural
network until it behaves as desired. \\

The past two decades have seen significant improvements in computational
capability and the availability of large data sets. Recent improved deep
learning algorithms have capitalised on this, using their immense flexibility to
tackle problems such as object detection \citep{krizhevsky_imagenet_2017} or
speech recognition \citep{toth_phone_2015}. To understand how these algorithms
work, we must look deeper into the structure of neural networks.

%
% Section: Structure
%


\subsection{Structure}

A neural network consists of many connected `neurons': nodes in the network each
holding some value, originally inspired by biological neurons in the brain
\citep{mcculloch1943}. In `feedforward' neural networks, these neurons are
organised into sequential layers as described above. The data is processed
through the neural network beginning at the input layer, with the outputs of one
layer (the neurons) becoming the inputs to the next, as shown in Figure
\ref{fig:nn} \citep{michelucci2018}. These layers can take a variety of forms.


\subsubsection{Input}
The first layer of a neural network is the input, which has neurons with values
that directly correspond to the data. This is often organised into either a
one-dimensional array or a two-dimensional matrix, with the latter primarily
used when analysing images, where each neuron in the matrix would correspond to
a pixel. Optionally, multiple `channels' can be used, which adds another
dimension to the data. This is typically used if the input is an RGB image, in
which case each pixel would have three values (one for the intensity of each
colour). In this case, three channels would be used, with each channel
representing the intensity of the given colour.\\

Data is often sent into the network in `batches'. This adds another dimension
to the input corresponding to the size of the batch. This has the advantage of
allowing much of the data to be fed through in parallel.

  \begin{figure}[t]%
    \centering
    \subfigure[]{%
      \label{fig:nn}%
      \includegraphics[height=2in]{nn.png}% 
    }%
    \qquad
    \subfigure[]{%
      \includegraphics[height=2in]{perceptatron.png}%
      \label{fig:perceptatron}%
    }%
    \caption[]{ \subref{fig:nn} A feedforward neural network with a single hidden layer.
      \textit{Image courtesy of Wikimedia commons\protect\footnotemark}.
      \subref{fig:perceptatron} A diagram of a single perceptron with inputs,
      \(x_i\), weights, \(w_i\), a bias, \(b\), an activation function,\(f\),
      and output, \(y\). \textit{Image courtesy of Dr Andrew Casey}.}
  \end{figure}

\footnotetext{https://upload.wikimedia.org/wikipedia/commons/4/46/Colored_neural_network.svg}



\subsubsection{Fully Connected Layer}
Neurons in a fully connected layer are modelled after the perceptron, originally
conceived by \citet{rosenblatt1958}, and take the form shown in Equation
\ref{eqn:perceptatron}. This consists of a weighted sum over the inputs $x_i$,
with some bias, $b$, and an activation function, $\varphi$, as shown below
\citep{reagen2017}:
\begin{align}
  \label{eqn:perceptatron}
  y = \varphi \left(\sum_{i}{w_i x_i} + b \right)\,.
\end{align}
\\

This can be represented with a graph such as the one in Figure
\ref{fig:perceptatron}. The use of the activation function was originally
inspired by the activation of organic neurons \citep{hodgkin1952}, with the idea
that the artificial neuron is only `activated' when the weighted sum of the
inputs is high enough. Rectified Linear Units (ReLUs) are perhaps the most
widely used activation function in modern neural networks and have been shown to
outperform traditional sigmoid activation functions \citep{glorot2011}. Figure
\ref{fig:activation} shows the sigmoid (left) and ReLU (right) activation
functions.\\


\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{sigmoid_v_relu.pdf}
  \caption{Comparison of ReLU (left) and sigmoid (right) activation functions.}
  \label{fig:activation}
\end{figure}

In a fully connected layer all neurons from one layer are connected to all
neurons in the next, hence the name. An example of one such fully connected
layer shown in Figure \ref{fig:fully_connected}. A single layer, \(L\), in a
neural network can be represented by a matrix of weights, \(W^{[L]}\), a
vector of biases \(\bm{b}^{[L]}\), and the activations (value of the neurons) of
that layer \(\bm{x}^{[L]}\). The activations of the next layer,
\(\bm{x}^{[L+1]}\) are then given by
\begin{align}
  \label{eqn:matrix_repr}
  \bm{x}^{[L+1]} &= \varphi \left(W^{[L]}\bm{x}^{[L]} +\bm{b}^{[L]}\right)\,.
\end{align}
\\

\noindent In component form, this is equivalent to
\begin{align}
  \label{eqn:component_repr}
  \bm{x}^{[L+1]}_i
  &= \varphi \left(\sum\limits_j \left(W^{[L]}_{ij}x^{[L]}_j\right) + b^{[L]}_i\right)\,,
\end{align}
where \(\bm{x}^{[1]} = \bm{x}\) would be the input of the network,
\(\bm{x}^{[n_L]} = \bm{y}\) would be the output of the network, and \(n_L\) is
the number of layers. In this case, the weights and biases would be the
parameters of the model, i.e.
\begin{align*}
  \bm{\theta} = \left\{W_{ij}^{[L]}, b_{k}^{[L]} \mid i, j, k, L \in \mathbb{N} \right\}\,.
\end{align*}

\begin{figure}[t]
  \centering
  \includegraphics[width=0.5\linewidth]{ann.png}
  \caption{The first two (fully connected) layers in a neural network
  represented as a graph. Each circular node represents a neuron, while the
  arrows and weights show the connections between them \citep{michelucci2018}.}
  \label{fig:fully_connected}
\end{figure}

\subsubsection{Convolutional layers}
\label{sec:convolutional}
Convolutional layers in neural networks are typically (although not necessarily)
used when analysing inputs with more than one dimension, such as images or
videos. A neural network consisting of mostly convolutional layers is called a
convolutional neural network. \\


\citet{hubel_receptive_1959} found that neurons in a cat's visual cortex fired
in response to properties of the sensory inputs, such as edges. This was the
inspiration for early convolutional architectures
\citep{fukushima_neocognitron_1980}. Unlike fully connected layers, the neurons
in a convolutional layer are organised into tensors of two or more dimensions.
This is then convolved with a `filter': a tensor that takes up a small portion
of the input. This filter is moved across the input in steps or `strides' of
some size, and the dot product between the filter and the section of input is
computed, which then makes up part of the input for the following layer (see
Figure \ref{fig:convolution}). This gives a measure for the difference between
the filter and the input area, with the idea that the filter will pick up some
feature from the input, for example, an edge in an image. This process typically
reduces the size of inputs between layers, and in this case, is called
downsampling. If the input is first `padded' with extra zeros, the same process
can increase the size of the inputs between layers in which case the process is
called upsampling or deconvolution (see Figure \ref{fig:upsampling}).
Furthermore, multiple filters may be used to create multiple output layers or
equivalently multiple slices of a higher-dimensional output layer. For example,
if two different filters were used on a two dimensional ($100 \times 100$) input,
the output would be a ($100 \times 100 \times 2$) layer with the last dimension
corresponding to each of the two filters. It should be noted that convolutional
layers are equivalent to a fully connected layer with specific weights held at
zero and non-zero weights (which correspond to a filter) are copied such that
the same filter is applied across the image (see again Figure
\ref{fig:convolution}). This mathematical equivalence means that the process of
training a network is the same regardless of whether convolutional or fully
connected layers are used.

\begin{figure}%
  \centering
  \subfigure[]{%
  \label{fig:convolution}%
  \includegraphics[height=2in]{convolution.png}}%
  \qquad
  \subfigure[]{%
  \label{fig:upsampling}%
  \includegraphics[height=2in]{upsampling.png}}%
  \caption[\subref{fig:convolution} Diagram of a convolutional layer \subref{fig:upsampling} Diagram of an upsampling layer]{\subref{fig:convolution} Diagram of a convolutional layer showing the input (blue) and the output (green). A filter is applied to a subset of the input (shaded blue) and the dot product between the entries of the filter and input is returned (shaded green). \\
  \subref{fig:upsampling} Diagram of an upsampling layer, showing the input (blue) with padding (white) and the output (green). Convolution is applied to this in the same way as in \subref{fig:convolution}, however the padding allows for the output to be larger then the original input.\\
  \textit{Both images generated from:} \url{https://github.com/vdumoulin/conv_arithmetic}.}
  \end{figure}

% Section: Learning
%
\subsection{Learning}
\label{sec:learning}
Typically a neural network learns its parameters, \(\bm{\theta}\), via
supervised learning. The network is first trained using known input/output pairs
\((\bm{x'}, \bm{y'})\), and the model can then be used for inference to estimate
the output (\(\bm{y}\)) of new inputs (\(\bm{x}\)) \citep{reagen2017}. This can
be represented as follows:
\begin{align*}
  (\bm{x'}, \bm{y'}) &\rightarrow NN(\bm{\theta}) && \text{Training} \\
  \bm{x} &\mathrel{\underset{NN}{\rightarrow}} \bm{y} && \text{Inference} \,.
\end{align*}
This training is typically done by using gradient descent, an iterative method
for finding a local minimum in a differentiable function \citep{cauchy_1847}. At
each iteration, beginning at some starting point, the gradient at the current
point is calculated, and a step is taken in the direction of the negative of the
gradient i.e. a step in the direction of the sharpest decline. A depiction of
gradient descent is shown in Figure \ref{fig:gradient_descent} using a contour
map. This has been applied to neural-network-like models since the 1960s
\citep{bryson1962steepest}, where the differentiable function in this case is
the cost function, \(C(\bm{\theta})\), a function in parameter space which gives
a measure for the distance between the outputs of the current model and the
desired outputs. By finding a minimum of this cost function, we effectively find
a point in parameter space with minimal distance between the actual outputs and
the desired outputs, i.e. we have a good model\footnote{This isn't actually
guaranteed, as gradient descent only finds a local minima, and not necessarily
the global minimum.}.\\

A cost function \(C_p\) can be calculated for the individual input/output pairs
\((\bm{x'}, \bm{y'})\). The total cost function, \(C_T\), is then given by the
average of the cost functions for all input/output pairs in the data, as shown
in Equation \ref{eqn:total cost}, where \(n_D\) is the total number of
input/output pairs in the training data.
\begin{align}
  C_T = \frac{1}{n_D} \sum\limits_{p} C_p \label{eqn:total cost}
\end{align}

These cost functions will often take the form of either the quadratic cost, also
known as the mean squared error, (Equation \ref{eqn:quadratic}), or the cross
entropy\footnote{Usually cross entropy is used when the outputs can be
represented as probability functions, i.e. \( 0 < y_i < 1\) and \(\sum y_i =
1\)} (Equation \ref{eqn:cross-entropy}).
\begin{align}
  C_p(\bm{\theta}, \bm{y}, \bm{y'}) &= \frac{1}{2} \sum\limits_{i}
    \left(y'_i - y_i\right)^2 && \text{Quadratic cost} \label{eqn:quadratic}\\
  C_p(\bm{\theta}, \bm{y}, \bm{y'}) &= - \sum\limits_{i}
  y'_i \log{y_i} && \text{Cross-entropy} \label{eqn:cross-entropy}
\end{align}
By minimising the cost function using gradient descent, the neural network
ideally learns the parameters that give a sensible output. To use traditional
gradient descent, the gradient of the total cost function would be calculated at
each step, requiring all the training data to be fed through the network before
taking a single step in parameter space, in addition to increasing the
computational cost of calculating the gradient.\\

To avoid this, stochastic gradient descent is typically used, where an
estimation of the gradient is used instead \citep{Bottou2010}. This estimation of
the gradient is calculated by only looking at a subset of the data (a batch) and
finding the gradient of the average cost function of this batch, i.e. finding
the gradient of:
\begin{align}
  C_B = \frac{1}{n_B} \sum\limits_{B} C_p \label{eqn:average cost}\,,
\end{align}
where \(n_B\) is the number of input/output pairs in the batch. Backpropagation
\citep{rumelhart_learning_1986} is typically used to calculate the gradient of
this average cost function.

\begin{figure}[t]
  \centering
  \includegraphics[width = 0.4\linewidth]{gradient_descent.png}
  \caption{Diagram showing gradient descent on a contour map. \textit{Image
  courtesy of wikimedia commons.}}
  \label{fig:gradient_descent}
\end{figure}


\subsubsection{Backpropagation}
By definition, the gradient of the average cost function is given by
\begin{align}
  \left(\nabla C_B\right)_i &= \partialderivative{C_B}{\theta_{i^{[L]}}} \,.
  \intertext{Using Equation \ref{eqn:average cost}, this gives:}
  \left(\nabla C_B\right)_i &=\frac{1}{n} \sum\limits_p \partialderivative{C_p}{\theta_i^{[L]}}\,.
  \label{eqn:backprop_deriv}
\end{align}

The goal of backpropagation is therefore to calculate the derivative in Equation
\ref{eqn:backprop_deriv} for each parameter \(\theta_i \in \bm{\theta} \)
\citep{Goodfellow-et-al-2016}. \\

From Equations \ref{eqn:quadratic} and \ref{eqn:cross-entropy}, we know that the
cost function is dependent on the output of the network, \(\bm{y}\), and the
desired output, \(\bm{y'}\). While \(\bm{y'}\) is fixed and does not depend on
the parameters of the network, the output \(\bm{y}\) is the activation of the
last layer of neurons (i.e. \(\bm{y} = \bm{x}^{[n_L]}\)), and is itself a
function of the previous layer of neurons, \(\bm{x}^{[n_L - 1]}\), the weights
of that layer, \(W^{[n_L - 1]}\), and the biases of that layer, \(\bm{b}^{[n_L -
1]}\) (see Equation \ref{eqn:matrix_repr}).\\

Using the chain rule, each derivative can then be framed in terms of the
activation of the neuron \(x_i^{[L+1]}\) that depends on the parameter
\(\theta_i^{L}\):
\begin{align}
  \partialderivative{C_p}{\theta_i^{[L]}} &=
  \partialderivative{x_i^{[L+1]}}{\theta_i^{L}}
  \partialderivative{C_p}{x_i^{[L+1]}}
\end{align}
\noindent
While the derivative \(\partial x_i^{[L+1]} / \partial \theta_i^{[L]} \) can
be directly computed using Equation \ref{eqn:matrix_repr}, the derivative
\(\partial C_p / \partial x_i^{[L+1]} \) requires more discussion.\\

If \(x_i^{[L+1]} = x_i^{[n_L]} = y_i\) (i.e. the neuron \(x_i^{[L+1]}\) is an
output neuron in the last layer), then the cost function will be defined
explicitly in terms of the activation of this neuron (Equations
\ref{eqn:quadratic} and \ref{eqn:cross-entropy}), and we can easily calculate
the derivative,
\begin{align}
  \partialderivative{C_p}{x_i^{[n_L]}} = C_p'\left(x_i^{[n_L]}\right)\,.
  \label{eqn:back_prop_1}
\end{align}
\\

However in general, this will not be the case and we must instead use an
iterative process to calculate this derivative. Since the activation of a neuron
in some layer, say \(x_i^{[L+1]}\), is a linear combination of the activation of
the neurons in the previous layer (see Equation \ref{eqn:matrix_repr}), we can
start with Equation \ref{eqn:back_prop_1}, and `propagate' backwards one layer
at a time to find the partial derivative of \(C_p\) with respect to the
activation of each neuron in the previous layer,
\begin{align}
  \partialderivative{C_p}{x_j^{[n_L - 1]}}
  &= \sum\limits_i \partialderivative{x_i^{[n_L]}}{x_j^{[n_L - 1]}}
  \partialderivative{C_p}{x_i^{[n_L]}} \,.
  \label{eqn:back_prop_2}
\end{align}
\\

\noindent We can therefore iterate through the following until we get to the layer
\(k-1\) (or equivalently \(L+1\)):
\begin{align}
  \partialderivative{C_p}{x_j^{[k - 1]}}
  &= \sum\limits_i \partialderivative{x_i^{[k]}}{x_j^{[k - 1]}}
  \partialderivative{C_p}{x_i^{[k]}}\,.
  \label{eqn:back_prop_3}
\end{align}
\\

\noindent Using Equation \ref{eqn:component_repr}, we can explicitly calculate each derivative
\begin{align}
  \partialderivative{x_i^{[k]}}{x_j^{[k - 1]}}
  &= \varphi'W_{ij}^{[k-1]}\,,
\end{align}
allowing us to calculate the gradient \(\nabla C_B\) of the average cost
function for the batch using Equation \ref{eqn:backprop_deriv}. Finally, with
the gradient found, we can now update the parameters of the network by taking a
step in the \(-\nabla C_B\) direction of parameter space. \\

Deep learning techniques based on the fully connected or convolutional neural
networks described above have been very successful at labelling problems such as
speech recognition, \citep{Hinton2012}, or image classification,
\citep{Krizhevsky2012}. However using these techniques to \textit{generate}
data had only experienced limited success before the recent introduction of
generative adversarial networks (GANs).\\

\subsection{Generative Adversarial Networks}
\label{sec:gan}
\citet{Goodfellow2014} introduced GANs as a way of generating
new data that `imitates' data from a given set. Rather than use a single
network, a GAN uses two separate neural networks, a generative network (the
generator) and a discriminative network (the discriminator), that compete
against each other such that the success of one network becomes the loss for the
other. In this process, the generative network learns to generate data similar
to the dataset while the discriminative network learns to distinguish between
samples either taken from the data distribution or generated by the generative
network \citep{Goodfellow2014}. The objective of the generative network is
therefore to increase the error-rate of the discriminative network. Notably, the
generator never actually sees the data it's trying to emulate, only the success
of the discriminator network. The only input to the generator is random noise,
which allows it to generate a new output each time. \\

An analogy of this process given by \citet{Goodfellow2014} is that the generative
network is a counterfeiter, trying to produce a fake currency without being
detected, while the discriminative network is the police, trying to detect the
counterfeit currency.\\

In a traditional GAN, the input of the generator, G, is some noise, \(\bm{z}\),
drawn from some predefined prior (\(\bm{z} \sim  p_z(\bm{z})\)), while
the output, \(G(\bm{z})\) is a mapping to the data distribution. Meanwhile the
input to the discriminator, D, is either samples, \(\bm{x}\), from the data
distribution, \(p_x\), or outputs of the generator, \(G(\bm{z})\). The output of
the discriminator, \(D(\bm{y})\), then represents the probability that the input
came from the data distribution (\( \bm{y} \sim p_{data}\)) and not from the
generator \(\bm{y} = G(\bm{z})\). The discriminator can therefore be trained to
maximise the probability of correctly identifying it's input with the
following cost function (see Section \ref{sec:learning})
\begin{align}
  C_D(D, G, \bm{\theta}_D, \bm{\theta}_G, \bm{x}, \bm{z}) &=
  -\log[D(\bm{x})] - \log[1 - D(G(\bm{z}))]\,,
\end{align}
and so minimising this cost function will maximise the probability of the
discriminator correctly identifying its input.\\

\noindent Conversely, the cost function for the generator is given by
\begin{align}
  C_G(D, G, \bm{\theta}_D, \bm{\theta}_G, \bm{x}, \bm{z})
  &= -C_D(D, G, \bm{\theta}_D, \bm{\theta}_G, \bm{x}, \bm{z})\\
  &= \log[D(\bm{x})] + \log[1 - D(G(\bm{z}))] \,.
  \label{eqn:generator_cost}
\end{align}

Early on in training, Equation \ref{eqn:generator_cost} might not be best suited
as a cost function, since the discriminator will easily be able to reject the
early generator outputs as they will be clearly distinct from the dataset
\citep{Goodfellow2014}. To avoid this, it may be more efficient to instead use
the following cost function at the start of training:
\begin{align}
  C_G(D, G, \bm{\theta}_D, \bm{\theta}_G, \bm{x}, \bm{z})
  &= -\log[D(G(\bm{z}))]\,.
\end{align}

Typically, training is done by alternating between training the generative network
and training the discriminative network until convergence. However GANs that
operate as described above are unable to take in any auxiliary information that
could allow it to condition the output of the generator.

\subsection{Conditional Generative Adversarial Networks}
\label{sec:cgan}
In \citeyear{mirza_conditional_2014}, \citeauthor{mirza_conditional_2014} first
introduced the idea of a conditional generative adversarial network (cGAN) as a
way to condition a GAN on some additional information, \(\bm{c}\), such as a
label or related data. While a traditional GAN is unsupervised and only needs an
input dataset which it learns to emulate, a cGAN is supervised and requires a
labelled dataset, i.e. many \((\bm{x}, \bm{c})\) pairs. This extra information
is fed into both networks allowing it to associate its output with this
additional information. A comparison between a GAN
and a cGAN is shown in Figure \ref{fig:gans}.\\


\begin{figure}[t]
  \centering
  \includegraphics[width = 0.6\linewidth]{gan_cgan.png}
  \caption{Comparison between a GAN (a) and a cGAN (b). In the GAN, noise
  (\(\bm{z}\)) is fed into the generator (\(G\)). The input to the discriminator
  (\(D\)) is then either the `fake' output of the GAN (\(G(\bm{z})\)) or the
  `real' data (\(\bm{x}\)). The discriminator decides if the input it has been
  given is real or fake. In the cGAN, both the generator and discriminator have
  an additional input (\(\bm{c}\)) which `conditions' the data
  \citep{mirza_conditional_2014}. In the case of an image-to-image GAN, this
  conditional data is an image, which is the only input to the generator. }
  \label{fig:gans}
\end{figure}


By conditioning a cGAN on images, this idea can be extended to image-to-image
translation \citep{isola2017image}. In this case, the only input to the generator
is the image \(\bm{c}\), from which the generator must produce an image
\(G(\bm{c})\) that closely matches \(\bm{x}\). For an image-to-image cGAN, the
cost function for the discriminator becomes
\begin{align}
  C_D(D, G, \bm{\theta}_D, \bm{\theta}_G, \bm{x}, \bm{c}) &=
  -\log[D(\bm{x}\mid \bm{c})] - \log[1 - D(G(\bm{c}))]\,,
\end{align}
while the cost function for the generator becomes
\begin{align}
  C_G(D, G, \bm{\theta}_D, \bm{\theta}_G, \bm{x})
  &= \log[D(\bm{x}\mid \bm{c})] + \log[1 - D(G(\bm{c}))]\,.
\end{align}


Image-to-image cGANs have a large potential for disruption in solar physics due
to the large number of images taken by spacecraft and terrestrial observatories
alike. While cGANs have already been used to generate solar magnetograms from EUV images
\citep{Kim2019}, and vice versa \citep{park_generation_2019}, there has been no
research into how they could be used to generate magnetograms from seismic maps.


%TODO: link

\begin{itemize}
  \item This is essential, as the only currently reliable way of imaging the solar
  farside is through farside helioseismic holography, with the generation of
  farside seismic maps.
  \item some research has been done to the correlation of seismic signitures and
  magnetic field (https://iopscience-iop-org.ezproxy.lib.monash.edu.au/article/10.1086/521592)
  \item research into detecting active regions from farside seismic maps ()
\end{itemize}


\begin{itemize}
  \item machine learning requires lots of data
  \item we have lots of freely available data
\end{itemize}





\section{Imaging the Sun}
\begin{itemize}
  \item While many Earth based solar observatories exist, space-based
  observatories are able to monitor the Sun without the limitation of
  atmospheric absorption.
  observing the Sun from
  Earth comes with many issues 
  \item The best way to image the Sun is directly from space-based telescopes.
  \item The Solar Dynamics Observatory (SDO) \citep{pesnell_solar_2012} orbits
  the Earth with a suite of instruments including the Atmospheric Imaging
  Assemply (AIA) \citep{lemen_atmospheric_2012} and the Helioseismic and
  Magnetic Imager (HMI) \citep{scherrer_helioseismic_2012}. Pertinent to this
  research, AIA is capable of taking extreme UV images of the full solar disk at
  a wavelength of \SI{304}{\angstrom}, while HMI is capable of taking full-disk
  magnetograms which measure the line-of-sight magnetic field, and full-disk
  dopplergrams which measure the line-of-sight motion of solar surface. As
  detailed in Section \ref{sec:FHSM}, these dopplergrams can be used to generate
  farside seismic maps. However by the nature of orbiting Earth, SDO is unable
  to image the solar farside except indirectly through farside helioseismic
  holography. Only three active solar probes, Parker Solar Probe, Solar Orbiter
  and Solar-Terrestrial Relations Observatory A (STEREO-A) measure the farside
  at any point in their orbit, and only STEREO-A consistently takes full-disk
  solar images. While STEREO-A does not produce magnetograms, the extreme
  ultraviolet imager on board images the Sun at a wavelenth of
  \SI{304}{\angstrom}. 

  Therefore, an indirect
  measurement of the magnetic field must be employed to reliably predict extreme
  space weather events.
  
  \citet{Kim2019} trained an image-to-image cGAN to generate artificial
  magnetograms from Extreme Ultraviolet (EUV) images. This training was done
  using pairs of \SI{304}{\angstrom} EUV images and magnetograms from SDO. This
  trained cGAN was then used to generate artificial farside magnetograms from
  similar STEREO-A EUV images.

  \item however they used a saturation point of 100 Gauss, limiting the ability
  to predict strong magnetic fields, especially considering that active regions
  can have magnetic field strengths of thousands of Gauss

  \item Furthermore, STEREO-A is currently on the nearside coming towards Earth
  and only has a partial view the solar farside (see Figure
  \ref{fig:stereo_pos}).

  \item As such the only consistent observation of the Farside comes from
  farside helioseismic holography.

  \item To generate farside magnetograms from seismic images using an
  image-to-image cGAN, we need to construct a dataset of seismic
  image/magnetogram pairs. However since we have no available farside
  magnetograms, the creation of this dataset presents it's own issue. To
  overcome this issue, we first train an image-to-image cGAN to generate
  magnetograms from \SI{304}{\angstrom} solar EUV images.

\end{itemize}



\begin{itemize}
  \item 
\end{itemize}

% Lit review stuff
% TODO: summary of what we will be doing


%
%
%
%
\chapter{Data Preparation}
\label{chap:data}
%
%
%
%

To generate farside magnetograms from farside seismic maps, we first create two distinct
data sets
\begin{enumerate}
  \item a nearside dataset consisting of EUV and magnetogram image pairs, and
  \item a farside dataset consisting of seismic map and EUV image pairs.
\end{enumerate}
As detailed in Chapter \ref{chap:training}, the farside EUV images will be used
to generate magnetograms, which can then be used to train an image-to-image cGAN
to generate magnetograms from farside seismic maps. Figure
\ref{fig:simple_diagram} shows a summary of the project pipeline. \\
\begin{figure}
  \centering
  \begin{tikzpicture}[node distance=4cm]

      % \draw[help lines] (0,0) grid (10cm,10cm);

      \coordinate (T) at (5,4);

      \node (SGAN) [cool, right of=T, left=0.0cm] {Seismic\\ GAN};
  
      \node (SM) [cool, left of=T, above=1cm, right=0.5cm] {Farside\\ Seismic Map};
      \node (STEM) [cool, left of=T, below=1cm, right=0.5cm] {STEREO Magnetogram};

      \node (SDO) [cool, left of=SM] {SDO: EUV and \\ Magnetogram};
      \node (UVGAN) [cool, left of=STEM] {UV\\ GAN};
      
      % \node (E) [cool] {STEREO EUV image};
      
      \node (FM) [cool, right of=SGAN] {Farside\\ Magnetogram};

      \coordinate (I1) at ([xshift=0.3cm]UVGAN.east);

      \node (SUV) [cool, below of=I1, above=1.5cm] {STEREO-A:\\ EUV};
      \draw [->] (SUV) -- node[anchor=west] {Inference} (I1);

      \coordinate (I2) at ([xshift=0.3cm]SGAN.east);

      \node (SM2) [cool, below of=I2, above=0.5cm] {Seismic\\ Map};
      \draw [->] (SM2) -- node[anchor=west] {Inference} (I2);

      \draw [line] (STEM) -| (T);
      \draw [line] (SM) -| (T);
      \draw [arrow] (T) -> node[anchor=east, xshift=-0.3cm] {Train}(SGAN);

      \draw [arrow] (SDO) -> node[anchor=west] {Train}(UVGAN);
      \draw [arrow] (UVGAN) -> (STEM);
      \draw [arrow] (SGAN) -> (FM);

      % \coordinate (FF) at ([xshift=-1.5cm]F.west); % we collect the edges in front of Q
      % \coordinate (MM) at ([xshift=-1.5cm]M.west); % we collect the edges in front of Q
      
      % \draw [arrow] (D) -- node[anchor=south, text width=2cm] {Helioseismic Holography} (P);
      % \draw [arrow] (MM) -- node[anchor=south] {cGAN} (M);
      % \draw [line] (P) -|  (FF);
      % \draw [line] (M) -|  (FF);
      % \draw [line] (S) -|  (MM);
      % % \draw [line] (E) -|  (MM);
      % \draw [arrow] (FF) -- node[anchor=south] {cGAN} (F);

  \end{tikzpicture}
  \caption{A simplified diagram of the project pipeline. Nearside SDO
  EUV/magnetogram image pairs are used to train the ``UV GAN'', which is then
  used to generate farside STEREO magnetograms. Farside seismic map/STEREO
  magnetogram pairs are then used to train the ``Seismic GAN'' which can then be
  used to generate farside magnetograms from nearside seismic maps without the
  need for STEREO data.}
  \label{fig:simple_diagram}
\end{figure}
To maximise effectiveness of each cGAN, we need to make the images consistent
across each dataset such that the only differentiation between images is the
change in solar activity. Furthermore, in each image-to-image translation we
need to ensure that the active regions are located in the same position in both the
input and output images. We must therefore account for the following effects
\begin{enumerate}[i]
  \item changes in time of image capture, 
  \item changes in location of image capture,
  \item the solar cycle in which the image was taken,
  \item position of the sun in images,
  \item orientation of the Sun in images,
  \item projection used in image,
  \item corrupted images or images with data artifacts,
  \item instrument degradation over time,
  \item instrument saturation, and
  \item amplitude of pixel values between image data-sets.
\end{enumerate}
In this chapter we detail how we obtain our data and prepare it for training,
accounting for above effects.

% \begin{itemize}
  
%   \item Nearside vs Farside (i.e. why we need it)
%   \item Data sources were:
%         \begin{itemize}
%           \item STEREO EUV images
%           \item SDO EUV images
%           \item SDO magnetograms
%           \item farside helioseismic holography maps
%         \end{itemize}
%   \item magnetograms measure the radial magnetic field, using filtegrams
%   \item %TODO: expand on how hmi works http://soi.stanford.edu/papers/dissertations/giles/thesis/PDF/chapter03.pdf
%   \item % https://link.springer.com/content/pdf/10.1007/s11207-011-9834-2.pdf
%   \item figure showing positions and trajectory of stereo, sun earth, SDO and
%         imaginary satellite for acoustic maps
%   \item figure (maybe the same one) showing plot of stereo position in
%   \item position data from http://www.srl.caltech.edu/STEREO/docs/position.html
%   \item This is in Heliocentric Earth equatorial (HEEQ): This system has its Z
%         axis parallel to the Sun's rotation axis (positive to the North) and its X
%         axis towards the intersection of the solar equator and the solar central
%         meridian as seen from the Earth. This system is sometimes known as
%         heliocentric solar (HS)
% \end{itemize}



\section{Data Collection}
Our research required the following data sources:
\begin{enumerate}
  \item SDO EUV images,
  \item SDO magnetograms,
  \item STEREO-A EUV images, and
  \item helioseismic holography maps.
\end{enumerate}
EUV images with a wavelength of \SI{304}{\angstrom} are produced by both the SDO
and STEREO EUV telescopes and were therefore choosen for this project. As explained in
Section \ref{sec:Sun}, light at \SI{304}{\angstrom} is emitted by the
chromosphere - the atmospheric layer above the photoshpere. \\

As SDO is orbiting the Earth, both the SDO EUV images and magnetograms were
taken of the nearside. STEREO-A is instead in a heliocentric orbit, with an
orbital period of 346 days. As such, it has rotated about the Sun relative to
Earth taking some images of the farside over the course of it's 14 year life.
Figure \ref{fig:stereo_pos} shows the location of STEREO-A over the course of
the mission. Finally, the seismic maps are generated from SDO dopplergrams, and
image the farside of the Sun as detailed in Section \ref{sec:FHSM}. \\

Of particular importance when collecting the data is the time of image capture, the
location of image capture, and the solar cycle in which the image was taken in.
Here we detail what decisions were made in regards to these factors.

% Changes in time of image capture
% Changes in location of image capture
% The solar cycle in which the image was taken


\subsection{Nearside Data}
As all the nearside data comes from SDO the position of the telescope does not
change between data types. Furthermore, SDO captures EUV images and magnetograms
with a cadence of 12 and 45 seconds respectively, allowing us to compare these
with very little time difference. The images were provided by the Joint Science
Operation Centre \footnote{See \url{http://jsoc.stanford.edu/}} and were
collected for every 12 hours between April 2010, when the first SDO data became
available, and December 2019 - the end of Solar cycle 24. Since all data was
taken during this solar cycle, we did not have to take into acount the flipping
of the global magnetic field which occurs between solar cycles (see Section
\ref{sec:dynamo}). Due to a combination of missing or poor quality images (see
Section \ref{sec:Data prep}) this process resulted in a total of 4247 nearside
EUV/magnetogram pairs.

\subsection{Farside Data}
\begin{itemize}
  \item need to compare EUV with seismic maps
  \item Why STEREO makes sense for this
  \item while the seismic maps are always generated for the solar farside, the
        EUV images captured by STEREO will only image the farside for some of
        it's orbit, as can be seen in Figure \ref{fig:stereo_pos}. This is
        further complicated by reduced telemetry rates with STEREO between August 2014 and
        January 2016, with complete instrument shut off between March and July
        2015, due to STEREO's superior solar conjunction. Details of this phase
        of the STEREO mission can be found in \citet{ossing_stereo_2017}.
        % https://stereo-ssc.nascom.nasa.gov/solar_conjunction.shtml
  \item Appendix \ref{app:fun orbit} shows the trajectory of STEREO A as it is
        leaving earth.
  \item As such, any STEREO image used would not be directly imaging the farside
  \item due to the rotation of the sun, the `face' of the Sun imaged by STEREO
  would also be imaged through farside helioseismic holography at a different
  time. For example, if STEREO imaged the Sun while \SI[]{45}[]{\degree} from
  the solar farside, after approximately 3 days, the Sun would have rotated
  such that the same `face' of the Sun would now be on the farside, and could be
  imaged by farside helioseismic holography.
  \item By using this rotation to our advantage, we can effectively compare
  farside seismic maps with not-quite-farside STEREO EUV images, albeit with
  some time delay between images.
  \item This method isn't perfect however, and has two primary drawbacks:
  \begin{enumerate}
    \item The differential rotation of the Sun means that active regions won't
    necessarily be in the same position after a time delay
    \item Active regions are constantly changing, for example new active regions may emerge on the surface over the course hours or days,
    while the decay of sunspots may last from days to weeks
    \citep{van_driel-gesztelyi_evolution_2015}.
  \end{enumerate}
  \item This will be discussed further in section \ref{chap:discussion}.

  \item To use this method, we must first determine the rotational period of the
  Sun
  \item This is not as obvious as it may at first seem, due to the Sun's
  differential rotation
  \item an appropriate choice for this period is given by the Carrington rotation.
  \item it is the average synodic rotational period of sunspots, which roughly
  corresponds to the synodic rotation of the Sun at a latitude of \(\SI[]{26}[]{\degree}\) \citep{carrington_observations_1863}
  \item this Carrington period is \(27.2753\) days which means it takes on average of \(27.2753\) days for a sunspot to rotate around the
  sun, relative to earth.

  \item In the heliocentric Earth Equatorial coordinate system, where the Z axis
 as the axis of solar rotation, and the x axis points from the centre of the sun the earth the angle between spacecraft and solar farside is given by:
\end{itemize}

\begin{align}
  \theta = \arctan{\frac{y}{x}}
\end{align}

- this gives:
\begin{align}
  t_{stereo} = t_{farside} + \frac{\theta}{2\pi}T
  \intertext{or equivalently:}
  t_{farside} = t_{stereo} - \frac{\theta}{2\pi}T
\end{align}
- using this, for each point in stereo time, i calculated the equivalent farside
time \\
- from this I download the FITS STEREO images that corresponded to the farside
images \\
- (farside are created every 12 hours between 2010 and now)

\begin{figure}[ht]
  \centering
  \includegraphics[width = 0.7\linewidth]{STEREO_pos.pdf}
  \caption[STEREO A Trajectory]{Trajectory of STEREO A between October 2006 and January 2021 in the
  Heliocentric Earth Equatorial coordinate system. In these coordinates, the Sun
  is at the origin with the Earth fixed on X axis. Each `bump' in STEREO's
  Trajectory correspond to a year on Earth. \textit{Image generated using
  data provided by Space Radiation Lab at California Institute of Technology.}}
  \label{fig:stereo_pos}
\end{figure}


\section{Image Projections}
% Position of the sun in images
% Orientation of the Sun in images
% Projection used in image

\begin{itemize}
  \item need to take into account the position of the Sun, the orientation of
  the Sun, and how the image was captured (i.e. what projection used - CCD with
  heloprojective cartiesian)
  \item To train the GAN, features of the Sun need to be in the same position in both
  the input and output training images.
  \item As there are many ways to project data from a three dimensional object
  (e.g. the Sun) on to a two dimensional image, this overlap is not guaranteed
  in general, even if two images are taken at the same place and time.
  \item therefore, to compare two different images of the Sun, the projection used
must be taken into account
\end{itemize}

\subsection{Nearside Data}
\begin{itemize}
  \item Fortunately both EUV and magnetogram images are taken by SDO at very similar
  times, and both sets of images are projected into helioprojective-cartesian
  coordinates.
  \item In this coordinate system, observations are projected against the
  celestial sphere, and positions are measured in the longitude \(\theta_x\) or
  latitude \(\theta_y\) of the celestial sphere, with the centre of the disk
  (i.e. the point of the Sun closest to the observer) at the origin.
  \item Note: this is not exactly correct, as the camera sensor (in this case a
  CCD detector) is a flat plane. As such, we are actually projecting on to a
  tangent plane of the celestial sphere (gnomonic projection). However since the
  angle subtended by the solar disk is \(\approx \SI[]{0.3}[]{\degree} \), this
  can be accurately approximated as a helioprojective projection. In fact, at a
  distance of 1 AU (approximately the orbital radius of SDO and STEREO), the
  angles on the tangent plane are the same as the angles on the celestial sphere
  to at least five significant figures \cite{thompson_w_t_coordinate_2006}
  %TODO: is this actually approximated like this?
  \item The helioprojective latitude and longitude of each pixel on the EUV and
  magnetogram images could be found using the metadata from each image.
  \item The instruments used to create these images are rotated relative to each
  other.
  \item to align the images, the images were rotated such that each column of
  vertical pixels had the same helioprojective longitude, and each row of pixels
  had the same helioprojective latitude.
  \item rotated such that the top of the image correspond to the northernmost part
  of the solar disk.
  \item however at different points of the orbit, the satellite is at a different
  distance from the sun, and so the relative size of the sun in each image will
  change throughout the one-year orbit.
  \item to remove this discrepancy, while also removing unnecessary pixels, the
  images were cropped to the radius of the sun, again using information
  extracted from the image metadata.
\end{itemize}

\subsection{Farside Data}
\begin{itemize}
  \item As the Stereo EUV data also used the same helioprojective-cartesian
  projection used for the nearside data, this data was prepared (?) in the same
  manner, first rotating the images before cropping them to the radius of the
  Sun.
  \item rotated such that the top of the image correspond to the northernmost part
  of the solar disk.
  \item this process was not so simple in the case of the farside helioseismic
  holography seismic maps.
  \item these images were instead projected into Carrington heliographic
  coordinates, where the positions are measured in latitude (\(\Theta\)) and
  Carrington longitude (\(\Phi_c\)).
  \item This coordinate system rotates with the Sun such that the prime meridian
  coincides with the central meridian (according to an observer on Earth)
  approximately every 27 days, depending on the position of Earth in it's orbit.
  \item As such, to directly compare the seismic maps with the STEREO EUV
  data, we must first project the seismic maps into helioprojective-cartesian
  coordinates.

  \item For each pixel in the final (helioprojective-cartesian) image, we need
  to find the corresponding point on the original (heliographic) image.
  \item In general this point will not match up exactly to the centre of a pixel
  on the original image and so an interpolation method needs to be used to find
  determine the value of the original pixel.
  \item to find this point we must first find the mapping from
  helioprojective-cartesian coordinates to Carrington heliographic coordinates.
  \item To do this, we use and intermediate transformation to
  heliocentric-cartesian coordinates. i.e.:
\end{itemize}

\begin{align*}
  \text{Helioprojective-cartesian} \rightarrow \text{Heliocentric-cartesian} \rightarrow \text{Carrington Heliographic}
\end{align*}

Heliocentric-cartesian coordinates give the true spatial position of an object
(x, y, z), with the centre of the Sun at the origin. The z-axis
points toward the observer, while the y-axis is in the plane containing the
z-axis and the rotational axis of the Sun. The x-axis is oriented such that the three axes
are orthogonal and create a right-hand coordinate system. \\

To convert helioprojective-cartesian coordinates into heliocentric-cartesian
coordinates, we use the following transformation, provided by
\citet{thompson_w_t_coordinate_2006}:
\begin{align}
  x &= d \cos \theta_y \sin \theta_x \, , \\
  y &= d \sin \theta_y \, and \\
  z &= D_\odot - \cos \theta_y \cos \theta_x \, .
  \label{eqn:heliop_to_helioc}
\end{align}
Where \(d\) is the distance is the distance between the observer and the point
being observed, and \(D_\odot\) is the distance between the observer and the centre of
the Sun. After some trigonometry, it can be shown that if the point being
observed is on the surface of the Sun, then
\begin{align}
  d &= D_0 \cos\theta - \sqrt{D_\odot^2 \left( \cos^2\theta - 1 \right) + R_\odot } \, , \\
  \intertext{where}
  \theta &= \cos^{-1}\left(\cos\theta_y \cos\theta_x \right) \, .
\end{align}

Similarly, we can convert from heliocentric-cartesian coordinates to carrignton heliographic
coordinates as follows:
\begin{align}
  \Theta &= \sin^{-1}\left( \frac{y \cos B_0 + z \sin B_0}{r}\right) \, , \\
  \Phi_c &= \arg (z \cos B_0 - y \sin B_0, x) + \Phi_{0} \,
  \intertext{where}
  r &= \sqrt{x^2 + y^2 + z^2} \, ,
\end{align}
and \(B_0\) and \(\Phi_{0}\) are the Carrington heliographic latitude and
longitude of the Observer. \\

\begin{itemize}
  \item This completes the required transformation, as the constants \(B_0\),
  \(\Phi_0\) and \(D_\odot\) can be obtained from the image metadata of each seismic
  map and corresponding STEREO EUV image we are comparing it too.
  \item Using this transformation, with bi-linear interpolation, we were able
  transform the STEREO Carrington heliographic images into
  Helioprojective-cartesian images that matched the STEREO IMAGES
  %TODO: reiterate that we want to match the seismic images with the stereo
  %images
  %TODO: compare stereo with transformed seismic maps
\end{itemize}


\section{Data pre-processing}
% Amplitude of pixel values between image data-sets
% Instrument degradation over time
% Instrument clipping
% Corrupted images or images with data artifacts

\label{sec:Data prep}


\begin{itemize}
  \item ok, so now that we have all the images fully aligned we now need to look
  at the images themselves
  \item Both the STEREO EUVI and SDO AIA use a Charge-coupled device (CCD) to
  image the Sun at a wavelength of
  \(\SI[]{304}[]{\angstrom}\) \citep{kaiser_stereo_2008,lemen_atmospheric_2012}.
  Each pixel in the CCD converts the incoming photons into electric charge,
  which is subsequently measured. This raw data is then processed to remove data
  artifacts caused by the imaging process, and the resulting image can then be
  used for analysis.  
  \item The value of each pixel (measured in digital number, or DN) on these images is then proportional to the
  solar spectral radiance over the width of the pixel.
\end{itemize}

\subsection{Ultraviolet Data}
\begin{itemize}
  \item From the 4313 AIA images used between 2010 and 2020, the pixel values
  for the AIA data range from \(\SI[]{-166}[]{DN}\) to \(\SI[]{16383}[]{DN}\).
  The get a handle on this data, a range of the pixel value percentiles were
  calculated for each image. This was plotted against time and can be seen in
  Figure \ref{fig:aia_percentiles}. Corrupted or otherwise poor quality images
  could then be identified due to the large irregularity in the percentiles of
  those images, as can be clearly seen in Figure \ref{fig:aia_outliers}. After
  reviewing the offending images, a simple threshold was used to remove the
  outliers.
  \item Had to consider the following effects:
  \begin{enumerate}
    \item corrupted images
    \item instrument degradation
    \item 
  \end{enumerate}
  \item Also apparent from Figure \ref{fig:aia_outliers} is the 
  \item However the 304\AA \ channel of SDO AIA is degrading over time
  \citep{boerner_photometric_2014}, effectively reducing the exposure of the
  image. Figures \ref{fig:aia_degradation} show a comparison in the exposures of
  images taken in 2011, 2015 and 2019 respectively. 
  \item To account for this, the pixel values of each image were given a
  weighting factor depending on the time the image was taken, i.e.
  \begin{align}
    p_f = w(t) p_i \, ,
  \end{align}
  where in this case $w(t)$ is the reciprocal of the rolling average of the 75th
  percentile at time $t$. This was picked as it had the lowest variance across
  50 point intervals ( was the most stable) indicating that it did not fluctuate
  with individual active regions, and was better representative of the quality
  of the instrument. The percentiles of the data after applying this
  weighting are shown in Figure \ref{fig:aia_no_degradation}.
  \item This method is not perfect, and some of the real trend in the data
  caused by the solar cycle was also inadvertently removed.
  \item while this is not ideal this mainly effects the quiet sun and had a
  smaller effect on the active regions.

  \item To ensure that the GAN trained on SDO data would carry over well to
  STEREO data, the STEREO data was normalised to match the SDO dataset.
  \item This is complicated by the fact that SDO and STEREO have different EUV
  instruments, and so the pixel values have different ranges. The percentiles of
  the STEREO data is shown in Figure \ref{fig:stereo_percentiles}.
  \item The gap in the STEREO data due to the aforementioned instrument shut off
  during STEREO's superior solar conjunction.
  \item To ensure the normalisation was consistent across both data sets,
  the STEREO data was shifted such that a pixel value of 0 was an equivalent UV
  intensity for both STEREO and SDO data.
  \item It was found that $\sim 3 \%$ of the SDO pixels had a value below 0,
  while the same percentage of STEREO pixels had a value below $\SI[]{725}[]{DN}$.
  \item Accordingly, the STEREO pixels were first shifted down by
  $\SI[]{725}[]{DN}$ before excluding outliers and accounting for instrument
  degradation using the same method as in the SDO data. This process is shown in
  Figures \ref{fig:stereo_shifted}, \ref{fig:stereo_outliers} and
  \ref{fig:stereo_no_degradation}.
  \item As can be seen in Figures \ref{fig:aia_percentiles} and
  \ref{fig:stereo_data_prep}, pixel values above $\approx \SI[]{2e4}[]{DN}$ are
  clipped by the instrument for both SDO and STEREO. However after accounting
  for instrument degradation and the offset of the STEREO data, the clipping
  becomes the wavy curve seen in Figures \ref{fig:aia_no_degradation} and
  \ref{fig:stereo_no_degradation}. To avoid the UV GAN learning any relation from
  this we introduced our own clipping that was uniform across both datasets.
  \item Since the STEREO data was clipped at a lower point than the AIA data,
  this uniform clipping point was chosen to be the minimum of a 50 point rolling
  average of the maximum pixel values across the STEREO data, which was $\sim \SI[]{32}[]{DN}$. This clipping
  point is also shown in Figure \ref{fig:stereo_no_degradation}.
  \item Any pixel values above this point or below zero were then clipped in both data sets.
  \item Finally the data was normalised by dividing by this clipping upper
  bound, such that all pixels across both data sets had values between 0 and 1.
  \item Figure \ref{fig:sdo_stereo_comparison} shows a comparison between the
  STEREO and SDO data sets after normalisation. As can be seen, the data still
  retains information about the solar cycle, with a peak in the middle of the
  solar cycle around 2014. This indicates that our normalisation has not over
  corrected, and is representative of the actual data. % reword
  \item Importantly both data sets appear very similar, allowing either to be
  inputs to the EUV GAN.
\end{itemize}



\subsection{Magnetogram Data}

\begin{itemize}
  \item The pixel percentiles for the SDO magnetogram data is shown in Figure
  \ref{fig:hmi_p}. Each pixel on the magnetogram measures the average radial
  magnetic field ($\mathbf{B}\cdot\mathbf{\hat{r}}$) in Gauss on the surface of
  the sun subtended by the pixel.
  \item As can be seen in Figure \ref{fig:hmi_p} the values of the pixels are
  almost perfectly mirrored across the x axis. This is explained by Gauss's
  law for magnetism,
  \begin{align}
    \oint \mathbf{B} \cdot \text{d}\mathbf{s} = 0 \,,
  \end{align}
  \item which in our case indicates that any positive radial magnetic field is
  likely accompanied by a negative magnetic field.
  \item Fortunately the magnetogram data did not have any noticeable instrument
  degradation and did not clip any data.
  \item Therefore the only normalisation required before using the data was
  dividing it by the absolute maximum pixel value across all the data, which in
  this case was $\SI[]{5847.6}[]{G}$, limiting the pixel values to between $-1$
  and $1$. 
  \item This ensured that the all magnetic field information was retained, while
  still being a suitable input to the EUV GAN.
\end{itemize}

\begin{figure}[t]%
  \centering
  \subfigure[]{%
    \label{fig:aia_2011}%
    \includegraphics[height=1.5in]{AIA_2011.01.01_00:00:00.png}% 
  }%
  \qquad
  \subfigure[]{%
    \includegraphics[height=1.5in]{AIA_2015.01.01_00:00:00.png}%
    \label{fig:aia_2015}%
  }%
  \qquad
  \subfigure[]{%
    \includegraphics[height=1.5in]{AIA_2019.01.01_00:00:00.png}%
    \label{fig:aia_2019}%
  }%
  \caption[]{Images taken by SDO AIA $\SI[]{304}[]{\AA}$ on the first of January in 2011
    \subref{fig:aia_2011}, 2012 \subref{fig:aia_2015} and 2019
    \subref{fig:aia_2019}. Due to the degradation of the instrument, the
    exposure reduces over time. \textit{Images courtesy of NASA.}}
  \label{fig:aia_degradation}
\end{figure}


\begin{figure}[t]%
  % \centering
  \subfigure[]{%
    \label{fig:aia_percentiles}
    \includegraphics[width=\linewidth]{AIA_percentiles.png}%
  }%
  \qquad
  \subfigure[]{%
    \label{fig:aia_outliers}%
    \includegraphics[width=\linewidth]{AIA_outliers.png}% 
  }%
  \qquad
  \subfigure[]{%
    \label{fig:aia_no_degradation}%
    \includegraphics[width=\linewidth]{AIA_no_degradation.png}% 
  }%

  \caption[]{\subref{fig:aia_percentiles} The percentiles of AIA data for images
  taken every 12 hours between May 2010 and December 2020. Due to the large
  range of data, the 25th to 100th percentiles where plotted on a log scale.
  \subref{fig:aia_outliers} The 75th percentile of the AIA data. A simple
  threshold was used to remove poor quality data.}
  \label{fig:aia_data_prep}
\end{figure}


\begin{figure}[t]%
  % \centering
  \subfigure[]{%
    \label{fig:stereo_percentiles}
    \includegraphics[width=\linewidth]{STEREO_percentiles.png}%
  }%
  \qquad
  \subfigure[]{%
  \label{fig:stereo_shifted}
  \includegraphics[width=\linewidth]{STEREO_shifted.png}%
}%
\qquad
\subfigure[]{%
\label{fig:stereo_outliers}
\includegraphics[width=\linewidth]{STEREO_outlier.png}%
}%
\qquad
\subfigure[]{%
\label{fig:stereo_no_degradation}
\includegraphics[width=\linewidth]{STEREO_no_degradation.png}%
}%
  
  \caption[]{}
  \label{fig:stereo_data_prep}
\end{figure}


\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{AIA_STEREO_normalised.png}
  \caption{Comparison of the SDO and STEREO data after normalisation.}
  \label{fig:sdo_stereo_comparison}
\end{figure}

\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{HMI_percentiles.png}
  \caption{}
  \label{fig:hmi_p}
\end{figure}
























%
%
%
%
%
%
%
%
\chapter{Training}
\label{chap:training}
%
%
%
%
%
%
%
%




\begin{itemize}
  \item with our data ready it is now time to train our networks.
  \item we want to create solar magnetograms from farside seismic images
  \item to do this, we requrie a training set of seismic image /magnetogram pairs
  \item since we only have dopplergrams of the farside, we first need to be able
  to generate a training set of farside magnetograms
  \item this can be done by first generating  magnetograms from UV images.
  \item Therefore we need to train two networks the first one generates
  magnetograms from UV data, and the second one to generate magnetograms from
  seismic data, using a training set created by the first network.

  \item Image-to-image cGANs have proven to be very effective at this task and
  make a suitable choice for such a task. As discussed in Section \ref{sec:gan},
  these consist of two competing neural networks, the generator and the
  discriminator. In this setup, the generator tries to `fool' the discriminator into
  predicting that the generated image is in fact real.



\end{itemize}



\begin{itemize}
  \item the process for creating a network capable of producing farside
  magnetograms from seismic maps consists of three parts.
  \begin{enumerate}
    \item The UV GAN is trained to generate magnetograms from uv images by using
    SDO UV/Magnetogram image pairs
    \item The now trained UV GAN is used to generate `STEREO' magnetograms from
    STEREO UV images
    \item The Seismic GAN is trained to generate magnetograms from Seismic
    images using STEREO magnetogram/ farside seismic image pairs.
  \end{enumerate}
  
  \item The same network model was used for parts 1. and 3., which consisted of
  a U-NET style generator, and a fully convolutional discriminator. Figure
  \ref{fig:solar_gans_diagram} shows a diagram of both GANs. This architecture
  for each GAN was based on the one used by \citet{Kim2019} for a very similar
  purpose.
\end{itemize}

\begin{figure}[h]
  \centering
  %TODO: this figure. see data analysis book for sketch. maybe different colours
  %for training gan/training
  \caption{Diagram of the UV-GAN and Seismic GAN.}
  \label{fig:solar_gans_diagram}
\end{figure}

%
%
%
%
%
\section{Architecture}
%
%
%
%
%
%

\subsection{Generator}





\begin{itemize}
  \item the generator part of each GAN must be able to translate between two
  images of the same size.
  \item A U-net \citep{ronneberger_u-net_2015} makes a suitable choice for this task
  \item U-nets consists of a down sampling path where the width and height of
  each layer gets
  smaller at each `block' followed by an upsampling path where the width and height
  get larger until it reaches the original size, making a symmetrical `U' shape.
  \item   Many `skip connections' join layers of the same size either side of
  the `U'. The model used in this work is shown in Figure \ref{fig:gen_model}.
  By using a U-Net, we are able to do image-to-image to image translation that
  is capable of retaining the shape and large scale structures of the original
  image while capturing small scale features and the interactions between these.
\end{itemize}
  
  \begin{figure}[h]
    \centering
    %TODO: fill out figure
    \caption{
      In our case, we start with a ($1024\times 1024$) input image and at each step
      in the down sampling path, apply convolution, batch normalisation and leaky
      reLU activation.% TODO need to explain these
      At each convoluitonal step an additional 64 filters are used than on the
      previous layer, maxing out at 512. The `bottom' layer 
    }
    \label{fig:gen_model}
  \end{figure}


  


\subsection{Discriminator}

\begin{itemize}
  \item The discriminator is given two inputs. The magnetogram (either real or
  generated) and the conditional image - a UV image in the case of the UV-GAN or
  a seismic map in the case of the Seismic-GAN. The network will then attempt to
  determine if the magnetogram input is either real or fake. The architecture of
  the discriminator used is shown in Figure~\ref{fig:discrim_model}. The output
  of the discriminator is a ($126\times 126$) array.
  \item when the discriminator is given a real magnetogtram, the discriminators
  goal is to maximise it's output, while if the discriminator is given a `fake'
  magnetogram the goal is to minimise it's output. Since the final layer of the
  descriminator has a sigmoid activation function the output of each output
  neuron is bounded between 0 and 1. A `perfect' discriminator would then output
  a tensor of $0$'s for a fake magnetogram input and a tensor of $1$'s for a
  real magnetogram. It should be noted that a perfect discriminator would
  paradoxically be bad, as this would prevent the generator from being able to
  learn. Similar to Section \ref{sec:gan}, the cost function for the
  discriminator is then given by


  \begin{align}
    C_{D(Real)} &= -\mathds{E}\left[\log(D(\mathbf{x}|\mathbf{c}))\right]
    \intertext{and,}
    C_{D(Fake)} &=  -\mathds{E}\left[\log(\mathds{1} -  D(G(\mathbf{c})|\mathbf{c}) ) \right]\,,
  \end{align} 


where $ C_{D(Real)}$ and $ C_{D(Fake)}$ are the discriminator cost functions
for real and fake magnetogram inputs respectively, $\mathbf{c}$ is the
"conditional" input to the GAN (either a UV image or a Seismic image, depending
on which GAN), $D(\dotsb|\mathbf{c})$ is the discriminator output with a real
($\mathbf{x}$) or fake ($G(\mathbf{c})$) magnetogram as an input, and
$\mathds{1}$ is a tensor full of $1$'s with the same shape as $D(\dotsb)$. In
each expression the `log' is taken element-wise, before the mean of all tensor
elements is taken. The total discriminator cost function is therefore given by
\begin{align}
  C_{D} = C_{D(Real)} + C_{D(Fake)} \,.
\end{align}

As explained in Section \ref{sec:cgan}, the discriminator also provides the cost
function for the generator. Unlike \ref{sec:cgan} an additional term was added
to minimise the absolute difference between the real and fake magnetograms. With
this addition, the generator cost function used was
\begin{align}
  C_{G} = -\mathds{E}\left[\log(D(G(\mathbf{c})|\mathbf{c}))\right] +
  100 \times \mathds{E}\left[|G(\mathbf{c} - \mathbf{x}|\right] \,.
\end{align} 


\end{itemize}



\begin{figure}[h]
  \centering
  %TODO: fill out figure
  \caption{
    The input consits of two ($1024\times 1024$) `channels', containing the
    magnetogram (be it real or fake) and the conditional image (either the UV
    image or seismic map depending on the GAN). 5 successive convolutional
    layers with batch normalisation and leaky ReLU activation were applied to
    reduce the final input to a ($126\times 126 \times 1$) tensor.
  }
  \label{fig:discrim_model}
\end{figure}



\section{UV-GAN}
\begin{itemize}
  \item The UV-GAN was trained using 4247 SDO UV/magnetogram image pairs
  captured during solar cycle 24 between April 2010 and December 2019. Images
  taken in November and December each year were used as the testing set, while
  the remaining 3505 image pairs were used as the training set. The GAN was run
  for $300000$ iterations at each step doing a forward (inference) and backward
  (training) pass of the discriminator before doing a forward and backward pass
  of the generator with a batch size of one. This small batch size means that,
  while potentially slower, the GAN will use less memory, and is less likely to
  result mode collapse - where the generator produces the same output regardless
  of the input. The training was done using the Adam optimizer
  \citep{kingma_adam_2014} with a learning rate (step size during gradient
  descent) of $0.0002$ and `momentum' parameters $\beta_1 = 0.5$, $\beta_2 =
  0.999$. The weights in the convolutional layers where initialised by
  \begin{align}
    w_c \sim \mathcal{N}\left(0, 0.02\right) \quad ,
  \end{align}
  while the weights for batch normalisation were initialised by
  \begin{align}
    w_b \sim \mathcal{N}\left(1.0, 0.02\right) \quad .
  \end{align}
  \item a kernal (filter) size of $4$ was used for the convoluitonal layers (see
  Section \ref{sec:convolutional}).
  \item After a first attempt at training the UV-GAN it was found that the GAN
  was unable to capture much of the lower-intensity magnetic structure of the
  active regions. This was thought to be due to the large dynamic range of both
  the UV images and magnetograms. This range is clearly seen in Figures
  \ref{fig:sdo_stereo_comparison} and \ref{fig:hmi_p}, where which in both cases
  show that approximately $99\%$ of the pixels in each image were at least an
  order of magnitude smaller than the maximum pixel values. This essentially
  results in images that are too dark, causing the GAN to largely focus on the
  few bright pixels. Previous work have used saturation limits to deal with this
  problem by clipping data above a certain point, \citet{Kim2019} for example
  used saturation limits of $\pm 100G$ for generating magnetograms. However this
  comes at the cost of utility, with the peak magnetic field in many sunspots
  exceeding $\SI[]{3000}[]{G}$. To avoid such a cut-off we instead artificially
  increased the saturation by taking the square-root of the pixel values for
  both the normalised magnetograms and UV images. Since the UV images had a
  pixel values between $0$ and $1$, this `boosted' dim pixels while
  avoiding the loss of any data. On the other hand the magnetograms had a
  pixel values between $-1$ and $1$ and so the artificial saturation took the form
  
\begin{align}
  x^{(\text{new})} = \text{Sign}(x)\sqrt{\absolutevalue{x}}\, ,
\end{align}

boosting pixels that had less intense magnetic fields. Importantly, this process
is completely reversible and the true magnetic field can be easily extracted.
Figure \ref{fig:artificial_sat} shows the pixel values before and after applying
this artificial saturation. 



\end{itemize}


\begin{figure}[h]
  \centering
  
  \caption{Percentiles of UV and magnetogram data before and after the artificial saturation}
  \label{fig:artificial_sat}
\end{figure}




\begin{itemize}
  \item Training the GAN again with the artificial saturation the GAN, we were able
  generate magnetograms that correctly replicated the shape of active regions.
  \item consistently underestimates magnetic field
  \item consistently gets shape
  \item doesn't consistently get polarities correct
  \item \ref{fig:aia_hmi_mag} shows a sample predicted magnetogram, along with
  the corresponding true 
\end{itemize}


\begin{figure}[t]%
  \includegraphics[width=\linewidth]{aia_hmi_mag.png}
  \caption[]{Taken on the 12th of November 2014. This image was part of the
  testing set and so was not used in training.}
  \label{fig:aia_hmi_mag}
\end{figure}

\begin{itemize}
  \item Using the UV GAN, we then went on to generate the STEREO magnetograms
  using 5087 STEREO UV images, between March 2011 and August 2019. These dates
  were chosen arbitrally such that the position of the Sun would mean that each
  image would be less than a seven day solar rotation from the Farside, and
  therefore a maximum of seven day time delay between the Farside and Stereo
  images.
  \item These STEREO magnetograms were then used for training the Seismic-GAN.
\end{itemize}


\section{Seismic-GAN}


\begin{itemize}
  \item the Seismic-GAN was initially trained using all the aforementioned
  magnetograms, along with the equivalent seismic maps.
  \item before training the Seismic-GAN, a mask was applied to the STEREO
  magnetograms `zero-out' any pixels outside the solar disk.
  \item once again, images taken in November or December were used for the test
  set with all other images used as part of the training set.
  
  \item The initial training resulted in a GAN that produced images that looked
  physically realistic to some degree, however did not match the STEREO
  magnetograms. i.e. the GAN was faking it. This is shown in Figure \ref{fig:default}.

  \item It was hypothesised that due to the 'blurriness' of the seismic images,
  i.e. changes happen over larger scales, we should use a larger filter size in
  the convolutional layers (see Section \ref{sec:convolutional})
  \item it was thought that this could potentially improve the generated
  magnetograms allowing the generator to learn from more large scale structures.

  \item The GAN was trained using a filter size of 16 (as apposed to 4)
  However training a GAN with this larger filter size resulted in
  mode-collapse, where the Generator found a local minimum by producing (almost)
  the same output image regardless of the input. This can be seen in
  Figure~\ref{fig:mode_collapse}.
  
  \item Finally the Seismic GAN was again trained with the smaller filter size, but now with a
  batch size of 8 as opposed to 1 (see Section \ref{sec: deep learning}). Figure
  \ref{fig:batch} shows an example magnetogram generated using this Seismic GAN.
  This time the GAN was able to predict some of the active regions, especially
  closer to the centre of the image (where the seismic maps are more accurate).
  \item However, there was a consistent bias in the images, and the GAN
  struggled to detect active regions closer to the edge of the disk, and often
  predicted active regions near the edge that didn't exist.

  \item to determine the usefulness of these magnetograms, we need to develop a
  metric for determining the accuracy of our predictions, in particular how
  capable it is at predicting extreme magnetic fields.

\end{itemize}


\begin{figure}[t]%
  \centering
  \subfigure[]{%
    \label{fig:6.11.11_def_STE}%
    \includegraphics[height=2in]{6.11.11_STE.png}% 
  }%
  \subfigure[]{%
    \label{fig:6.11.11_def_MAG}%
    \includegraphics[height=2in]{6.11.11_MAG.png}% 
  }\\%
  \subfigure[]{%
    \label{fig:6.11.11_def_smap}%
    \includegraphics[height=2in]{6.11.11_smap.png}% 
  }%
  \subfigure[]{%
  \label{fig:6.11.11_default}%
  \includegraphics[height=2in]{6.11.11_default.png}% 
  }%
  \caption[]{Images relating to the first attempt of training the Seismic GAN.
  \subref{fig:6.11.11_def_STE} is a STEREO EUV image taken on 31st of October 2011,
  \subref{fig:6.11.11_def_MAG} is the corresponding magnetogram generated by
  the UV GAN, \subref{fig:6.11.11_def_smap} is the equivalent Siesmic Map taken
  on 6th of November 2011 and
  \subref{fig:6.11.11_default} is the corresponding magnetogram generated by the
  Seismic GAN.}
  \label{fig:default}
\end{figure}


\begin{figure}[t]%
  \centering
  \subfigure[]{%
    \label{fig:6.11.11_ker_smap}%
    \includegraphics[height=2in]{6.11.11_smap.png}% 
  }%
  \subfigure[]{%
  \label{fig:6.11.11_kernal}%
  \includegraphics[height=2in]{6.11.11_16kernal.png}%
  } \\
  \subfigure[]{%
  \label{fig:16.11.06_ker_smap}%
  \includegraphics[height=2in]{16.11.06_smap.png}%
  }%
  \subfigure[]{%
  \label{fig:16.11.06_kernal}%
  \includegraphics[height=2in]{16.11.06_16kernal.png}%
  }%
  \caption[]{\subref{fig:6.11.11_ker_smap} and \subref{fig:6.11.11_kernal}
  show a seismic map taken on the 6th of November 2011 and the corresponding
  magnetogram genreated by the Seismic GAN, after training it with a larger
  kernal size. \subref{fig:16.11.06_ker_smap} shows a seismic map taken 5 years
  later on the 6th of Novermber 2016, while \subref{fig:16.11.06_kernal} shows
  the corresponding generated magnetogram. Despite the different dates and
  seismic maps, the Seismic GAN generates the same magnetogram.}
  \label{fig:mode collapse}
\end{figure}


\begin{figure}[t]%
  \centering
  \subfigure[]{%
    \label{fig:6.11.11_STE}%
    \includegraphics[height=2in]{6.11.11_STE.png}% 
  }%
  \subfigure[]{%
    \label{fig:6.11.11_MAG}%
    \includegraphics[height=2in]{6.11.11_MAG.png}% 
  }\\
  \subfigure[]{%
    \label{fig:6.11.11_smap}%
    \includegraphics[height=2in]{6.11.11_smap.png}% 
  }%
  \subfigure[]{%
  \label{fig:6.11.11_batch}%
  \includegraphics[height=2in]{6.11.11_batch.png}% 
  }%
  \caption[]{}
  \label{fig:batch}
\end{figure}

%
%
%
%
%
%
%
%
\chapter{Results \& Analysis}
%
%
%
%
%
%




\begin{itemize}
  \item How do we analyse the data?
  \item absolute difference of images is a bad idea because:
  \begin{itemize}
    \item difficult to interpret error
    \item the surface area of the sun corresponding to a given pixel changes
    with radius (i.e. pixels at the solar limb will correspond to a larger
    section of the Sun than pixels in the centre of the image).
    \item This means that the magnetic field will be unevenly weighted towards
    the central pixels
  \end{itemize}
  \item An alternative to this is to calculate the total magnetic flux of a
  given image, and compare this to the total magnetic flux of the Sun half a
  rotation later
  \item this can be done with the following steps
  \begin{enumerate}
    \item for each pixel, find the helioprojective coordinates
  \end{enumerate}
\end{itemize}

\begin{align}
  \theta_x &= \Delta x (x - c_x) \, \text{, and} \\
  \theta_y &= \Delta y (y - c_y)
\end{align}

where  \((\Delta x, \Delta y)\) are the dimensions of one pixel in arcseconds,
\( (x, y) \) is the image coordinates of the pixel, and \( (c_x, c_y) \) is the
image coordinates of the centre of the disk. The dimensions and coordinates of
the centre of the disk could be obtained from the image metadata. The
helioprojective coordinates of each corner of each pixel can then be found by
adding/subtracting \(\frac{1}{2} (\Delta x, \Delta y)\). Using Equation
\ref{eqn:heliop_to_helioc}, we can convert these helioprojective coordinates
into heliocentric coordinates, i.e. the true spatial positions \((x, y, z)\) of
the four points \((\bm{a}, \bm{b}, \bm{c}, \bm{d})\) on the surface of the Sun.
To approximate the area subtended by the given pixel, we split these four points
into two triangles defined by the vectors \((\bm{c}-\bm{a}, \bm{b} - \bm{a}) \)
and \((\bm{c}-\bm{a}, \bm{d} - \bm{a}) \). The areas of these triangles can be
found 
\begin{align}
  A = \frac{1}{2} \abs*{\bm{v}_1 \times \bm{v}_2} \, ,
\end{align}


where \(\bm{v}_1\), \(\bm{v}_2\) are the vectors defining the triangle. By
summing over the areas of both triangles, we obtain an estimate of the surface
area corresponding to each pixel. Multiplying it by the magnitude of the
magnetic field measured at the pixel, we obtain the magnitude of the magnetic
flux of the pixel. Summing over all pixels gives us the total unsigned magnetic
flux, \(\bm{\phi}\), for that image. Figure \ref{fig:tumf_calc} shows an example
of the unsigned magnetic field, area and unsigned magnetic flux.


\begin{figure}[t]%
  \centering
  \subfigure[]{%
    \label{fig:tumf_calc_1}%
    \includegraphics[height=2.5in]{tumf_calc_1.png}% 
  }%
  \qquad
  \subfigure[]{%
    \label{fig:tumf_calc_2}%
    \includegraphics[height=2.5in]{tumf_calc_2.png}% 
  }%
  \qquad
  \subfigure[]{%
    \label{fig:tumf_calc_3}%
    \includegraphics[height=2.5in]{tumf_calc_3.png}% 
  }%
  \caption[]{The unsigned magnetic field \subref{fig:tumf_calc_1}, area
  \subref{fig:tumf_calc_2} and unsigned
  magnetic flux \subref{fig:tumf_calc_3} calculated using a HMI magnetogram,
  taken on 5th May, 2010.}
  \label{fig:tumf_calc}
\end{figure}


\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{Flux_vs_time.png}
  \caption{Total Unsigned Magnetic Flux according to SDO (Blue), the UV GAN
  (orange) and the Seismic GAN (Green) as a function of time. }
  \label{fig:flux_vs_time}
\end{figure}


%
%
%
%
%
\chapter{Discussion}
\label{chap:discussion}
%
%
%
%
%

\begin{itemize}
  \item poorly accounted for the long term trend from the degradation
  \item how we could have done it better
  \item could potentially improve uv gan by setting a higher lower bound on
  clipping (we don't need low intensity information). Similar for seismic gan.

  \item it is likely that the siesmic disturbance and UV light contain any
  information about the magnetic polarity (direction) of a given active region.
  \item It was postulated that their might be enough information for the network
  to learn an indirect relationship between the polarity and the siesmic
  disturbance/UV light through the context of the image - for example Hale's law
  can be used to predict the polarity of the leading sunspot.
  \item
\end{itemize}

% Experiment with # layers etc

% test on fake images - analyse how it works

% Use a piGAN (physically informed GAN Use a better gan
% https://openaccess.thecvf.com/content_CVPRW_2020/papers/w11/Alshehhi_Deep_Regression_for_Imaging_Solar_Magnetograms_Using_Pyramid_Generative_Adversarial_CVPRW_2020_paper.pdf

% use recurrent neural network

% do it all in one i.e. nearside dopplergrams -> farside magnetograms

% compare directly to nearside mag rather than farside generated mag

% Could help boundary conditions for dynamo models “since large-scale flux is
% generated by the deep-seated dynamo, the observed characteristics of flux
% emergence and that of the subsequent decay provide vital clues as well as
% boundary conditions for dynamo models”
% https://link.springer.com/article/10.1007%2Flrsp-2015-1 

% use smaller gan for seismic GAN (not 1024 by 1024)



% Copied from earlier:
% \item By using this rotation to our advantage, we can effectively compare
%   farside seismic maps with not-quite-farside STEREO EUV images, albeit with
%   some time delay between images.
%   \item This method isn't perfect however, and has two primary drawbacks:
%   \begin{enumerate}
%     \item The differential rotation of the Sun means that active regions won't
%     necessarily be in the same position after a time delay
%     \item Active regions are constantly changing, for example new active regions may emerge on the surface over the course hours or days,
%     while the decay of sunspots may last from days to weeks
%     \citep{van_driel-gesztelyi_evolution_2015}.
%   \end{enumerate}
%   This will be discussed further in section \ref{chap:discussion}.



\chapter*{Conclusion}

\bibliographystyle{mnras.bst}

\bibliography{ml.bib, imaging.bib,space_weather.bib,sun.bib,hsm.bib, Bibliography.bib}


\appendix

\chapter{Coordinate Systems}
For a description of solar coordinate systems, see
\citet{thompson_w_t_coordinate_2006}.

\chapter{STEREO orbit}
\label{app:fun orbit}
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.8\linewidth]{fun_orbit.png}
  \caption{Trajectory of STEREO spacecraft as it leaves the Earth and uses a gravity assist from the moon to reach it's orbit}
  \label{fig:fun_orbit}
\end{figure}

\chapter{just getting things down quickly}



\section{STEREO Magnetogram GAN}
- for the gan the input magnetograms and the seismic maps images needed to have
the same dimensions - while the seismic maps were 180 by 180 pixels, the
magnetograms were 1024 by 1024 pixels.

% currently thinking of upsampling seismic maps then downsampling magnetograms,
% but commented out paragraph shows my initial idea

% - to make them the same dimension, the magnetograms were resampled using
%   bicubic interpolation to the size of the seismic maps. This interpolation
%   method was chosen as it results in a smoother resampling with fewer
%   interpolation artifacts \citep{keys_cubic_1981}.


- to make them the same dimension, the seismic maps were resampled using bicubic
interpolation to the size of the magnetograms. This interpolation method was
chosen as it results in a smoother resampling with fewer interpolation artifacts
\citep{keys_cubic_1981}.



\end{document}

